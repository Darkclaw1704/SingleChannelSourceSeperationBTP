{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07a4fb46",
   "metadata": {},
   "source": [
    "## CTDRN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f78e17",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-12T15:46:39.639074Z",
     "iopub.status.busy": "2025-11-12T15:46:39.638936Z",
     "iopub.status.idle": "2025-11-12T15:46:40.731363Z",
     "shell.execute_reply": "2025-11-12T15:46:40.730407Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.5.1+cu121\n",
      "CUDA available: True\n",
      "CUDA version: 12.1\n",
      "cuDNN version: 90100\n",
      "Device count: 1\n",
      "GPU Name: NVIDIA L40S\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"CUDA version:\", torch.version.cuda)\n",
    "print(\"cuDNN version:\", torch.backends.cudnn.version())\n",
    "print(\"Device count:\", torch.cuda.device_count())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU Name:\", torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3706c230",
   "metadata": {},
   "source": [
    "===== Phase 1: Core Complex Layers for CTDCRN (PyTorch) =====\n",
    "Implements:\n",
    "- ComplexConv1dPacked  (Eq. 9–10 style complex 1D conv in a single call)\n",
    "- ComplexGlobalLayerNorm (complex global LN per channel across time)\n",
    "- ComplexLeakyReLU (separate real/imag activations)\n",
    "- ComplexLSTM (Eq. 11–12 from the paper)\n",
    "- Quick sanity test to validate shapes & numerical behavior\n",
    "\n",
    "Input/Output convention everywhere: (B, 2, C, T)\n",
    "    dim=1 is [real, imag] stacked; C=channels/feature maps, T=time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671382f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-12T15:46:40.734993Z",
     "iopub.status.busy": "2025-11-12T15:46:40.734790Z",
     "iopub.status.idle": "2025-11-12T15:46:40.885259Z",
     "shell.execute_reply": "2025-11-12T15:46:40.884515Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK — channels preserved across all blocks: torch.Size([4, 2, 64, 128])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import math\n",
    "from typing import Optional\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# --- housekeeping: good defaults for your LS-class GPU ---\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.set_float32_matmul_precision(\"high\")  # PyTorch ≥ 2.0\n",
    "\n",
    "# If you're on a 30-core CPU, use them for CPU-side ops:\n",
    "try:\n",
    "    torch.set_num_threads(30)\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "\n",
    "# ---------- helpers: pack/unpack complex ----------\n",
    "def _stack_complex(r: torch.Tensor, i: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Stack real & imag to channel-1 => shape (B, 2, C, T).\"\"\"\n",
    "    return torch.stack([r, i], dim=1)\n",
    "\n",
    "def _split_complex(x: torch.Tensor):\n",
    "    \"\"\"Split (B, 2, C, T) into (r, i) each (B, C, T).\"\"\"\n",
    "    assert x.dim() == 4 and x.size(1) == 2, f\"Expected (B,2,C,T), got {tuple(x.shape)}\"\n",
    "    return x[:, 0].contiguous(), x[:, 1].contiguous()\n",
    "\n",
    "\n",
    "# ---------- activation ----------\n",
    "class ComplexLeakyReLU(nn.Module):\n",
    "    \"\"\"Apply LeakyReLU independently to real & imaginary parts.\"\"\"\n",
    "    def __init__(self, negative_slope: float = 0.01, inplace: bool = False):\n",
    "        super().__init__()\n",
    "        self.relu = nn.LeakyReLU(negative_slope=negative_slope, inplace=inplace)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        r, i = _split_complex(x)\n",
    "        return _stack_complex(self.relu(r), self.relu(i))\n",
    "\n",
    "\n",
    "class ComplexGlobalLayerNormPhasePreserving(nn.Module):\n",
    "    \"\"\"\n",
    "    Complex Global Layer Norm (phase-preserving).\n",
    "    Uses a single shared variance (r and i normalized together)\n",
    "    to preserve the phase angle of each complex activation.\n",
    "    Input/Output: (B, 2, C, T)\n",
    "    \"\"\"\n",
    "    def __init__(self, num_channels: int, eps: float = 1e-8, affine: bool = True):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.affine = affine\n",
    "        if affine:\n",
    "            self.gamma = nn.Parameter(torch.ones(num_channels))\n",
    "            self.beta_r = nn.Parameter(torch.zeros(num_channels))\n",
    "            self.beta_i = nn.Parameter(torch.zeros(num_channels))\n",
    "        else:\n",
    "            self.register_parameter(\"gamma\", None)\n",
    "            self.register_parameter(\"beta_r\", None)\n",
    "            self.register_parameter(\"beta_i\", None)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        r, i = _split_complex(x)  # (B,C,T)\n",
    "        mean_r = r.mean(dim=-1, keepdim=True)\n",
    "        mean_i = i.mean(dim=-1, keepdim=True)\n",
    "        r_c = r - mean_r\n",
    "        i_c = i - mean_i\n",
    "\n",
    "        # Shared variance across r and i to preserve phase\n",
    "        var = (r_c.pow(2) + i_c.pow(2)).mean(dim=-1, keepdim=True)\n",
    "        inv_std = torch.rsqrt(var + self.eps)\n",
    "\n",
    "        r_n = r_c * inv_std\n",
    "        i_n = i_c * inv_std\n",
    "\n",
    "        if self.affine:\n",
    "            g = self.gamma.view(1, -1, 1)\n",
    "            br = self.beta_r.view(1, -1, 1)\n",
    "            bi = self.beta_i.view(1, -1, 1)\n",
    "            r_n = r_n * g + br\n",
    "            i_n = i_n * g + bi\n",
    "\n",
    "        return _stack_complex(r_n, i_n)\n",
    "\n",
    "def _same_padding_1d(kernel_size: int, dilation: int) -> int:\n",
    "    # preserves length for stride=1, odd kernels\n",
    "    return ((kernel_size - 1) * dilation) // 2\n",
    "\n",
    "\n",
    "# ---------- complex conv1d (single kernel call, fast) ----------\n",
    "class ComplexConv1dPacked(nn.Module):\n",
    "    \"\"\"\n",
    "    Complex 1D convolution using a single F.conv1d on concatenated inputs.\n",
    "\n",
    "    Given Wr, Wi ∈ R^{Cout × Cin × K} and input (xr, xi) ∈ R^{B×Cin×T}:\n",
    "      y_r = conv(xr, Wr) - conv(xi, Wi)\n",
    "      y_i = conv(xi, Wr) + conv(xr, Wi)\n",
    "    We implement this by building the block weight:\n",
    "      [[Wr, -Wi],\n",
    "       [Wi,  Wr]]\n",
    "    and calling conv1d once on [xr; xi] ∈ R^{B×(2Cin)×T}.\n",
    "\n",
    "    Input:  (B,2,Cin,T)\n",
    "    Output: (B,2,Cout,T)\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size,\n",
    "                 stride: int = 1, padding: Optional[int] = None,\n",
    "                 dilation: int = 1, bias: bool = True):\n",
    "        super().__init__()\n",
    "        if padding is None:\n",
    "            padding = _same_padding_1d(kernel_size, dilation)   # <-- FIX\n",
    "        self.in_c = in_channels\n",
    "        self.out_c = out_channels\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.dilation = dilation\n",
    "\n",
    "        # Learn real/imag filters\n",
    "        self.Wr = nn.Parameter(torch.empty(out_channels, in_channels, kernel_size))\n",
    "        self.Wi = nn.Parameter(torch.empty(out_channels, in_channels, kernel_size))\n",
    "\n",
    "        if bias:\n",
    "            self.br = nn.Parameter(torch.zeros(out_channels))\n",
    "            self.bi = nn.Parameter(torch.zeros(out_channels))\n",
    "        else:\n",
    "            self.register_parameter('br', None)\n",
    "            self.register_parameter('bi', None)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "# In model.py, inside ComplexConv1dPacked AND ComplexConvTranspose1dPacked\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        # 1. Use correct Kaiming for LeakyReLU\n",
    "        nn.init.kaiming_uniform_(self.Wr, a=0.01, nonlinearity='leaky_relu')\n",
    "        nn.init.kaiming_uniform_(self.Wi, a=0.01, nonlinearity='leaky_relu')\n",
    "        \n",
    "        # 2. Scale down by 1/sqrt(2) because Complex = Real + Imag\n",
    "        #    (Var(Real) + Var(Imag) = 2 * Var. We want 1 * Var.)\n",
    "        with torch.no_grad():\n",
    "            self.Wr.div_(math.sqrt(2))\n",
    "            self.Wi.div_(math.sqrt(2))\n",
    "\n",
    "        if hasattr(self, 'br') and self.br is not None:\n",
    "            nn.init.zeros_(self.br)\n",
    "            nn.init.zeros_(self.bi)\n",
    "\n",
    "            \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        r, i = _split_complex(x)  # (B,Cin,T)\n",
    "        xin = torch.cat([r, i], dim=1)  # (B, 2Cin, T)\n",
    "\n",
    "        # Assemble block weight: (2*Cout, 2*Cin, K)\n",
    "        top = torch.cat([self.Wr, -self.Wi], dim=1)\n",
    "        bot = torch.cat([self.Wi,  self.Wr], dim=1)\n",
    "        W = torch.cat([top, bot], dim=0)\n",
    "\n",
    "        # Bias maps to [br - bi, br + bi]\n",
    "        if self.br is not None:\n",
    "            # FIX: map biases to [real, imag] blocks directly\n",
    "            b = torch.cat([self.br, self.bi], dim=0)\n",
    "        else:\n",
    "            b = None\n",
    "\n",
    "        y = F.conv1d(\n",
    "            xin, W, b,\n",
    "            stride=self.stride, padding=self.padding, dilation=self.dilation, groups=1\n",
    "        )  # (B, 2*Cout, T)\n",
    "\n",
    "        yr, yi = torch.split(y, self.out_c, dim=1)\n",
    "        return _stack_complex(yr, yi)\n",
    "\n",
    "\n",
    "# ---------- complex LSTM (two real LSTMs) ----------\n",
    "class ComplexLSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    Correct CLSTM per paper:\n",
    "      Lr = LSTMr(Pr) - LSTMi(Pi)\n",
    "      Li = LSTMr(Pi) + LSTMi(Pr)\n",
    "    I/O: (B,2,C,T) -> (B,2,H,T)\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size: int, hidden_size: int,\n",
    "                 num_layers: int = 1, bias: bool = True,\n",
    "                 bidirectional: bool = False, dropout: float = 0.0):\n",
    "        super().__init__()\n",
    "        self.hr = nn.LSTM(input_size, hidden_size, num_layers=num_layers, bias=bias,\n",
    "                          batch_first=True, bidirectional=bidirectional, dropout=dropout)\n",
    "        self.hi = nn.LSTM(input_size, hidden_size, num_layers=num_layers, bias=bias,\n",
    "                          batch_first=True, bidirectional=bidirectional, dropout=dropout)\n",
    "        self.out_channels = hidden_size * (2 if bidirectional else 1)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        r, i = _split_complex(x)                # (B,C,T)\n",
    "        r_t = r.transpose(1, 2).contiguous()    # (B,T,C) == P_r\n",
    "        i_t = i.transpose(1, 2).contiguous()    # (B,T,C) == P_i\n",
    "\n",
    "        # Run hr on [Pr, Pi] in one go, then split\n",
    "        hr_in = torch.cat([r_t, i_t], dim=0)    # (2B, T, C)\n",
    "        hr_out, _ = self.hr(hr_in)              # (2B, T, H)\n",
    "        hr_Pr, hr_Pi = torch.chunk(hr_out, 2, dim=0)  # each (B, T, H)\n",
    "\n",
    "        # Run hi on [Pi, Pr] in one go (note the order), then split\n",
    "        hi_in = torch.cat([i_t, r_t], dim=0)    # (2B, T, C)\n",
    "        hi_out, _ = self.hi(hi_in)              # (2B, T, H)\n",
    "        hi_Pi, hi_Pr = torch.chunk(hi_out, 2, dim=0)  # each (B, T, H)\n",
    "\n",
    "        # Mix per the equations\n",
    "        Lr = hr_Pr - hi_Pi                      # (B, T, H)\n",
    "        Li = hr_Pi + hi_Pr                      # (B, T, H)\n",
    "\n",
    "        # Back to (B,2,H,T)\n",
    "        Lr = Lr.transpose(1, 2).contiguous()\n",
    "        Li = Li.transpose(1, 2).contiguous()\n",
    "        return _stack_complex(Lr, Li)\n",
    "\n",
    "\n",
    "# ---------- quick sanity test ----------\n",
    "def _sanity_tests(device=\"cpu\"):\n",
    "    # === Option A: keep channels constant across conv/norm/act/LSTM ===\n",
    "    # Choose a working width C (paper-style values: 32/64/128 are common)\n",
    "    C = 64\n",
    "    T = 128\n",
    "    B = 4\n",
    "\n",
    "    x = torch.randn(B, 2, C, T)  # pretend this is CHE output with C channels\n",
    "\n",
    "    conv = ComplexConv1dPacked(in_channels=C, out_channels=C, kernel_size=3)   # C -> C\n",
    "    # Use the PHASE-PRESERVING normalization we discussed:\n",
    "    norm = ComplexGlobalLayerNormPhasePreserving(num_channels=C)\n",
    "    act  = ComplexLeakyReLU(negative_slope=0.01)  # tweak to 0.05/0.1 if training saturates\n",
    "    lstm = ComplexLSTM(input_size=C, hidden_size=C, num_layers=1)              # C -> C\n",
    "\n",
    "    y1 = conv(x)    ; assert y1.shape == (B, 2, C, T)\n",
    "    y2 = norm(y1)   ; assert y2.shape == (B, 2, C, T)\n",
    "    y3 = act(y2)    ; assert y3.shape == (B, 2, C, T)\n",
    "    y4 = lstm(y3)   ; assert y4.shape == (B, 2, C, T)\n",
    "\n",
    "    print(\"OK — channels preserved across all blocks:\", y4.shape)\n",
    "\n",
    "\n",
    "_sanity_tests(\"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a193ee",
   "metadata": {},
   "source": [
    "===== Phase 2: Mid-Stack Encoding & Dilated Residual Blocks for CTDCRN (PyTorch) =====\n",
    "Implements:\n",
    "\n",
    "CHE — Complex Hierarchical Encoder (Fig. 2): Conv(C→M) → cGLN (phase-preserving) → Conv(M→C)\n",
    "\n",
    "CDCM — Complex Dilated Convolution Module (Fig. 3): Conv → cLeakyReLU → cGLN → D-Conv(d) → cLeakyReLU → cGLN → Conv + residual\n",
    "\n",
    "CDCMStack — TasNet-style dilation schedule repeated across N layers\n",
    "\n",
    "Utility make_dilations — cycles exponential dilations (e.g., 1,2,4,8,16,32,64,128, …)\n",
    "\n",
    "Input/Output convention everywhere: (B, 2, C, T)\n",
    " dim=1 packs [real, imag]; C = complex channels (feature maps), T = time frames. All ops are complex-aware and channel-preserving unless stated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d918fbd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-12T15:46:40.887343Z",
     "iopub.status.busy": "2025-11-12T15:46:40.887165Z",
     "iopub.status.idle": "2025-11-12T15:46:40.972211Z",
     "shell.execute_reply": "2025-11-12T15:46:40.971429Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase-2 sanity: {'che_out': (2, 2, 64, 256), 'cdcm_out': (2, 2, 64, 256), 'stack_out': (2, 2, 64, 256)}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# ---------- CHE (Complex Hierarchical Encoder) ----------\n",
    "class CHE(nn.Module):\n",
    "    \"\"\"\n",
    "    Complex Hierarchical Encoder (paper Fig. 2):\n",
    "      Conv(C_in→M) → ComplexNorm → Conv(M→C_out)\n",
    "    No activation inside (paper shows only normalization).\n",
    "    \"\"\"\n",
    "    def __init__(self, in_ch: int, mid_ch: int, out_ch: int, ksize: int = 3):\n",
    "        super().__init__()\n",
    "        self.conv1 = ComplexConv1dPacked(in_ch, mid_ch, kernel_size=ksize, stride=1)\n",
    "        self.norm  = ComplexGlobalLayerNormPhasePreserving(mid_ch)\n",
    "        self.conv2 = ComplexConv1dPacked(mid_ch, out_ch, kernel_size=ksize, stride=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.conv1(x)\n",
    "        y = self.norm(y)\n",
    "        y = self.conv2(y)\n",
    "        return y\n",
    "\n",
    "\n",
    "\n",
    "# ---------- CDCM (Complex Dilated Convolution Module) ----------\n",
    "class CDCM(nn.Module):\n",
    "    \"\"\"\n",
    "    CDCM block (Fig. 3, Sec. C):\n",
    "      ComplexConv(C->C) -> LeakyReLU -> cGLN ->\n",
    "      Complex Dilated Conv(C->C, dilation=d) ->\n",
    "      LeakyReLU -> cGLN -> ComplexConv(C->C)\n",
    "      Residual sum with input (real+imag added respectively).\n",
    "    Notes:\n",
    "      • D-CONV = complex conv with dilation \"d\".\n",
    "      • Keep channels constant (Option A) so residual x + f(x) is valid.\n",
    "    \"\"\"\n",
    "    def __init__(self, channels: int, ksize: int = 3, dilation: int = 1, slope: float = 0.01):\n",
    "        super().__init__()\n",
    "        C = channels\n",
    "        # 1) complex conv (no dilation)\n",
    "        self.conv1 = ComplexConv1dPacked(C, C, kernel_size=ksize, stride=1, dilation=1)\n",
    "        self.norm1 = ComplexGlobalLayerNormPhasePreserving(C)\n",
    "        self.act1  = ComplexLeakyReLU(negative_slope=slope)\n",
    "\n",
    "        # 2) complex dilated conv (D-CONV in the paper)\n",
    "        self.dconv = ComplexConv1dPacked(C, C, kernel_size=ksize, stride=1, dilation=dilation)\n",
    "        self.norm2 = ComplexGlobalLayerNormPhasePreserving(C)\n",
    "        self.act2  = ComplexLeakyReLU(negative_slope=slope)\n",
    "\n",
    "        # 3) final complex conv to produce residual branch output\n",
    "        self.conv2 = ComplexConv1dPacked(C, C, kernel_size=ksize, stride=1, dilation=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.conv1(x)\n",
    "        y = self.norm1(self.act1(y))\n",
    "\n",
    "        y = self.dconv(y)\n",
    "        y = self.norm2(self.act2(y))\n",
    "\n",
    "        y = self.conv2(y)\n",
    "        # Residual: sum real and imag parts respectively\n",
    "        return x + y\n",
    "\n",
    "\n",
    "# ---------- Utility: make a dilation schedule like TasNet / paper ----------\n",
    "def make_dilations(n_layers: int, base_cycle=(1, 2, 4, 8, 16, 32, 64, 128)):\n",
    "    \"\"\"\n",
    "    Repeat an exponential dilation cycle to length n_layers.\n",
    "    Example: n_layers=12 -> [1,2,4,8,16,32,64,128,1,2,4,8]\n",
    "    \"\"\"\n",
    "    dil = []\n",
    "    while len(dil) < n_layers:\n",
    "        dil.extend(base_cycle)\n",
    "    return dil[:n_layers]\n",
    "\n",
    "\n",
    "# ---------- CDCM stack (sequential modules with residual inside each) ----------\n",
    "class CDCMStack(nn.Module):\n",
    "    \"\"\"\n",
    "    A sequence of CDCM blocks with a chosen dilation schedule.\n",
    "    \"\"\"\n",
    "    def __init__(self, channels: int, n_layers: int,\n",
    "                 ksize: int = 3, slope: float = 0.01,\n",
    "                 base_cycle=(1,2,4,8,16,32,64,128)):\n",
    "        super().__init__()\n",
    "        dilations = make_dilations(n_layers, base_cycle)\n",
    "        self.blocks = nn.ModuleList([\n",
    "            CDCM(channels=channels, ksize=ksize, dilation=d, slope=slope)\n",
    "            for d in dilations\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        for b in self.blocks:\n",
    "            x = b(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# ---------- Quick sanity aligning with the paper ----------\n",
    "def _phase2_sanity():\n",
    "    torch.manual_seed(0)\n",
    "    B, C, T = 2, 64, 256\n",
    "    x = torch.randn(B, 2, C, T, device=\"cpu\")\n",
    "\n",
    "    # CHE: expand to M then reduce back to C\n",
    "    M = 128\n",
    "    che = CHE(in_ch=C, mid_ch=M, out_ch=C, ksize=3)\n",
    "    y = che(x); assert y.shape == (B,2,C,T)\n",
    "\n",
    "    # CDCM: keep channels constant, residual inside\n",
    "    cdcm = CDCM(channels=C, ksize=3, dilation=4, slope=0.01)\n",
    "    z = cdcm(y); assert z.shape == (B,2,C,T)\n",
    "\n",
    "    # Stack a few CDCMs with TasNet-style dilations\n",
    "    stack = CDCMStack(channels=C, n_layers=6, ksize=3, slope=0.01)\n",
    "    o = stack(z); assert o.shape == (B,2,C,T)\n",
    "\n",
    "    return {\"che_out\": tuple(y.shape), \"cdcm_out\": tuple(z.shape), \"stack_out\": tuple(o.shape)}\n",
    "\n",
    "print(\"Phase-2 sanity:\", _phase2_sanity())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ce41de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-12T15:46:40.973781Z",
     "iopub.status.busy": "2025-11-12T15:46:40.973631Z",
     "iopub.status.idle": "2025-11-12T15:46:41.100844Z",
     "shell.execute_reply": "2025-11-12T15:46:41.100209Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase-3 sanity: {'out0': (2, 2, 1, 512), 'out1': (2, 2, 1, 512), 'params': 897924, 'dbg': {'mask_mag_r': 0.7605569362640381, 'mask_mag_i': 0.760753333568573, 'predec_energy_r': 3.345418930053711, 'predec_energy_i': 3.334362030029297}}\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from typing import Optional, Dict, Any, List\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F  # (2) import safety\n",
    "\n",
    "# assumes Phase-1/2 symbols exist in scope:\n",
    "# _stack_complex, _split_complex, ComplexLeakyReLU,\n",
    "# ComplexGlobalLayerNormPhasePreserving, ComplexConv1dPacked,\n",
    "# ComplexLSTM, CDCM, CDCMStack, CHE, apply_crm_eq13, _same_padding_1d\n",
    "\n",
    "# -------------------------------\n",
    "# Mask head (independent CRMs)\n",
    "# -------------------------------\n",
    "class MaskHeadCRM(nn.Module):\n",
    "    \"\"\"Predict complex masks per source independently. Output: (B, 2, S, C, T)\"\"\"\n",
    "    def __init__(self, channels: int, n_sources: int = 2):\n",
    "        super().__init__()\n",
    "        self.S = n_sources\n",
    "        self.head = ComplexConv1dPacked(channels, channels * n_sources, kernel_size=1, stride=1, dilation=1)\n",
    "        self.act  = nn.Tanh()  # bound per-part masks ∈ [-1, 1]\n",
    "\n",
    "    def forward(self, feat: torch.Tensor) -> torch.Tensor:\n",
    "        m_raw = self.head(feat)                         # (B,2,S*C,T)\n",
    "        B, two, SC, T = m_raw.shape\n",
    "        C = SC // self.S\n",
    "        return self.act(m_raw.view(B, two, self.S, C, T))\n",
    "\n",
    "\n",
    "# -----------------------------------------\n",
    "# Complex Transposed Conv (packed) utility\n",
    "# -----------------------------------------\n",
    "class ComplexConvTranspose1dPacked(nn.Module):\n",
    "    \"\"\"\n",
    "    Complex transposed 1D conv using a single conv_transpose1d on packed [r;i].\n",
    "    Input:  (B, 2, Cin, T)  -> Output: (B, 2, Cout, T_out)\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size,\n",
    "                 stride: int = 1, padding: int = 0, output_padding: int = 0,\n",
    "                 dilation: int = 1, bias: bool = True):\n",
    "        super().__init__()\n",
    "        self.in_c, self.out_c = in_channels, out_channels\n",
    "        self.stride, self.padding = stride, padding\n",
    "        self.output_padding, self.dilation = output_padding, dilation\n",
    "\n",
    "        # conv_transpose1d expects weight: (Cin, Cout, K)\n",
    "        self.Wr = nn.Parameter(torch.empty(in_channels, out_channels, kernel_size))\n",
    "        self.Wi = nn.Parameter(torch.empty(in_channels, out_channels, kernel_size))\n",
    "        if bias:\n",
    "            self.br = nn.Parameter(torch.zeros(out_channels))\n",
    "            self.bi = nn.Parameter(torch.zeros(out_channels))\n",
    "        else:\n",
    "            self.register_parameter('br', None)\n",
    "            self.register_parameter('bi', None)\n",
    "        self.reset_parameters()\n",
    "\n",
    "# In model.py, inside ComplexConv1dPacked AND ComplexConvTranspose1dPacked\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        # 1. Use correct Kaiming for LeakyReLU\n",
    "        nn.init.kaiming_uniform_(self.Wr, a=0.01, nonlinearity='leaky_relu')\n",
    "        nn.init.kaiming_uniform_(self.Wi, a=0.01, nonlinearity='leaky_relu')\n",
    "        \n",
    "        # 2. Scale down by 1/sqrt(2) because Complex = Real + Imag\n",
    "        #    (Var(Real) + Var(Imag) = 2 * Var. We want 1 * Var.)\n",
    "        with torch.no_grad():\n",
    "            self.Wr.div_(math.sqrt(2))\n",
    "            self.Wi.div_(math.sqrt(2))\n",
    "\n",
    "        if hasattr(self, 'br') and self.br is not None:\n",
    "            nn.init.zeros_(self.br)\n",
    "            nn.init.zeros_(self.bi)\n",
    "\n",
    "            \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        r, i = _split_complex(x)              # (B,Cin,T)\n",
    "        xin = torch.cat([r, i], dim=1)        # (B,2Cin,T)\n",
    "\n",
    "        top = torch.cat([ self.Wr, -self.Wi], dim=1)  # (Cin, 2*Cout, K)\n",
    "        bot = torch.cat([ self.Wi,  self.Wr], dim=1)  # (Cin, 2*Cout, K)\n",
    "        W   = torch.cat([top, bot], dim=0)            # (2*Cin, 2*Cout, K)\n",
    "\n",
    "        b = None\n",
    "        if self.br is not None:\n",
    "            b = torch.cat([self.br, self.bi], dim=0)  # (2*Cout,)\n",
    "\n",
    "        y = F.conv_transpose1d(\n",
    "            xin, W, b,\n",
    "            stride=self.stride, padding=self.padding,\n",
    "            output_padding=self.output_padding, dilation=self.dilation, groups=1\n",
    "        )  # (B, 2*Cout, T_out)\n",
    "\n",
    "        yr, yi = torch.split(y, self.out_c, dim=1)\n",
    "        return _stack_complex(yr, yi)\n",
    "\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# Decoder mirroring CHE: C -> che_mid -> 1 (ksize)\n",
    "# ---------------------------------------------------\n",
    "class ComplexDecoderMirrorCHE(nn.Module):\n",
    "    \"\"\"\n",
    "    Mirror of CHE using complex transpose-convs with the same ksize.\n",
    "    (1) C -> che_mid -> 1 with optional phase-preserving norm between.\n",
    "    \"\"\"\n",
    "    def __init__(self, channels: int, che_mid: int, ksize: int = 3, use_norm: bool = True):\n",
    "        super().__init__()\n",
    "        assert ksize % 2 == 1, \"Use odd ksize to preserve length with stride=1\"\n",
    "        pad = _same_padding_1d(ksize, dilation=1)\n",
    "\n",
    "        self.deconv1 = ComplexConvTranspose1dPacked(channels, che_mid, kernel_size=ksize,\n",
    "                                                    stride=1, padding=pad, dilation=1)\n",
    "        self.norm    = ComplexGlobalLayerNormPhasePreserving(che_mid) if use_norm else None\n",
    "        self.deconv2 = ComplexConvTranspose1dPacked(che_mid, 1, kernel_size=ksize,\n",
    "                                                    stride=1, padding=pad, dilation=1)\n",
    "\n",
    "    def forward(self, z: torch.Tensor) -> torch.Tensor:\n",
    "        y = self.deconv1(z)\n",
    "        if self.norm is not None:\n",
    "            y = self.norm(y)\n",
    "        y = self.deconv2(y)\n",
    "        return y  # (B,2,1,T)\n",
    "\n",
    "\n",
    "# -----------------------------------------\n",
    "# One separation link (per source)\n",
    "# -----------------------------------------\n",
    "class CTDCRNLink(nn.Module):\n",
    "    \"\"\"\n",
    "    CDCM-A -> CLSTM -> Norm -> CDCM-B -> Mask(1) -> CRM -> Decoder(mirror CHE)\n",
    "    Provides optional debug metrics for monitoring (5).\n",
    "    \"\"\"\n",
    "    def __init__(self, channels: int, che_mid: int, ksize: int,\n",
    "                 n_cdcm_a: int, n_cdcm_b: int, slope: float, dil_cycle):\n",
    "        super().__init__()\n",
    "        C = channels\n",
    "        self.cdcm_a = CDCMStack(channels=C, n_layers=n_cdcm_a, ksize=ksize, slope=slope, base_cycle=dil_cycle)\n",
    "        self.clstm  = ComplexLSTM(input_size=C, hidden_size=C, num_layers=1, bidirectional=False)\n",
    "        self.post_lstm_norm = ComplexGlobalLayerNormPhasePreserving(C)\n",
    "        self.cdcm_b = CDCMStack(channels=C, n_layers=n_cdcm_b, ksize=ksize, slope=slope, base_cycle=dil_cycle)\n",
    "\n",
    "        self.mask_head = MaskHeadCRM(channels=C, n_sources=1)\n",
    "        # (1) stronger decoder mirroring CHE with same ksize and che_mid\n",
    "        self.decoder   = ComplexDecoderMirrorCHE(channels=C, che_mid=che_mid, ksize=ksize, use_norm=True)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _debug_metrics(self, masked_feat: torch.Tensor, mask: torch.Tensor) -> Dict[str, torch.Tensor]:\n",
    "        # masked_feat: (B,2,C,T), mask: (B,2,1,C,T)\n",
    "        m_mag = mask.abs().mean(dim=(-2, -1))           # (B,2,1)\n",
    "        predec_energy = (masked_feat ** 2).mean(dim=(-2, -1))  # (B,2)\n",
    "        return {\n",
    "            \"mask_mag_r\": m_mag[:, 0, 0].mean(),  # scalars\n",
    "            \"mask_mag_i\": m_mag[:, 1, 0].mean(),\n",
    "            \"predec_energy_r\": predec_energy[:, 0].mean(),\n",
    "            \"predec_energy_i\": predec_energy[:, 1].mean(),\n",
    "        }\n",
    "    @staticmethod\n",
    "    def apply_crm_eq13(feat: torch.Tensor, mask: torch.Tensor):\n",
    "        zr, zi = feat[:, 0], feat[:, 1]\n",
    "        Mr, Mi = mask[:, 0], mask[:, 1]\n",
    "        Qr = zr.unsqueeze(1) * Mr - zi.unsqueeze(1) * Mi\n",
    "        Qi = zr.unsqueeze(1) * Mi + zi.unsqueeze(1) * Mr\n",
    "        Q = torch.stack([Qr, Qi], dim=2)\n",
    "        Qs = Q.permute(0, 2, 1, 3, 4).unbind(dim=2)\n",
    "        return list(Qs)\n",
    "    def forward(self, z_enc: torch.Tensor, return_debug: bool = False):\n",
    "        z = self.cdcm_a(z_enc)\n",
    "        z = self.post_lstm_norm(self.clstm(z))\n",
    "        z = self.cdcm_b(z)\n",
    "\n",
    "        m  = self.mask_head(z)             # (B,2,1,C,T)\n",
    "        Qs = self.apply_crm_eq13(z, m)          # list len=1, each (B,2,C,T)\n",
    "        y  = self.decoder(Qs[0])           # (B,2,1,T)\n",
    "\n",
    "        if return_debug:\n",
    "            dbg = self._debug_metrics(Qs[0], m)\n",
    "            return y, dbg\n",
    "        return y\n",
    "\n",
    "\n",
    "# ----------------\n",
    "# CTDCRN (2 links)\n",
    "# ----------------\n",
    "class CTDCRN(nn.Module):\n",
    "    \"\"\"\n",
    "    Shared CHE encoder, then two independent links (one per source).\n",
    "    Defaults set to paper-like depths (3).\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 channels: int = 64,\n",
    "                 che_mid: int = 128,\n",
    "                 ksize: int = 3,\n",
    "                 n_src: int = 2,\n",
    "                 n_cdcm_a: int = 8,   # (3) paper-ish defaults\n",
    "                 n_cdcm_b: int = 8,   # (3)\n",
    "                 slope: float = 0.01,\n",
    "                 dil_cycle=(1,2,4,8,16,32,64,128)):\n",
    "        super().__init__()\n",
    "        assert n_src == 2, \"Paper uses two sources; extend if needed.\"\n",
    "        assert ksize % 2 == 1, \"Use odd ksize to preserve length\"\n",
    "        self.che = CHE(in_ch=1, mid_ch=che_mid, out_ch=channels, ksize=ksize)\n",
    "        self.links = nn.ModuleList([\n",
    "            CTDCRNLink(channels, che_mid, ksize, n_cdcm_a, n_cdcm_b, slope, dil_cycle)\n",
    "            for _ in range(n_src)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x: torch.Tensor, return_debug: bool = False):\n",
    "        # x: (B,2,1,T)\n",
    "        z = self.che(x)  # (B,2,C,T)\n",
    "        if return_debug:\n",
    "            outs: List[torch.Tensor] = []\n",
    "            debugs: List[Dict[str, Any]] = []\n",
    "            for link in self.links:\n",
    "                y, dbg = link(z, return_debug=True)\n",
    "                outs.append(y)\n",
    "                debugs.append(dbg)\n",
    "            # aggregate simple monitor signals across links\n",
    "            agg = {k: torch.stack([d[k] for d in debugs]).mean() for k in debugs[0].keys()}\n",
    "            return outs, agg\n",
    "        else:\n",
    "            return [link(z) for link in self.links]\n",
    "\n",
    "\n",
    "# ----------------\n",
    "# Quick sanity\n",
    "# ----------------\n",
    "def _ctdcrn_phase3_sanity():\n",
    "    torch.manual_seed(0)\n",
    "    B, T, C = 2, 512, 64\n",
    "    x = torch.randn(B, 2, 1, T)\n",
    "    # keep stacks small for fast sanity; defaults are 8/8 (3)\n",
    "    model = CTDCRN(channels=C, che_mid=128, ksize=3, n_src=2, n_cdcm_a=2, n_cdcm_b=2, slope=0.01)\n",
    "    outs, dbg = model(x, return_debug=True)\n",
    "    assert len(outs) == 2\n",
    "    assert outs[0].shape == (B,2,1,T) and outs[1].shape == (B,2,1,T)\n",
    "    n_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    return {\"out0\": tuple(outs[0].shape), \"out1\": tuple(outs[1].shape), \"params\": n_params,\n",
    "            \"dbg\": {k: float(v) for k, v in dbg.items()}}\n",
    "\n",
    "print(\"Phase-3 sanity:\", _ctdcrn_phase3_sanity())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1e41f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from rml_dataloader import get_dataloaders\n",
    "# import torch\n",
    "\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# H5_PATH = \"/home/bss/data/GOLD_XYZ_OSC.0001_1024.hdf5\"\n",
    "# MODS = [\"BPSK\", \"QPSK\"]   # MUST match the .py script\n",
    "# FRAC = 0.20               # MUST match\n",
    "# SEED = 1337               # MUST match\n",
    "# SNR_MIN = 0               # MUST match\n",
    "# SNR_MAX = 18              # MUST match\n",
    "# BATCH_SIZE = 32\n",
    "\n",
    "# train_loader, val_loader, test_loader = get_dataloaders(\n",
    "#     h5_path=H5_PATH,\n",
    "#     mods=MODS,\n",
    "#     frac=FRAC,\n",
    "#     batch_size=BATCH_SIZE,\n",
    "#     seed=SEED,\n",
    "#     snr_min=SNR_MIN,\n",
    "#     snr_max=SNR_MAX,\n",
    "#     num_workers=4,\n",
    "#     pin_memory=True,\n",
    "# )\n",
    "\n",
    "# for xb, yb in train_loader:\n",
    "#     xb = xb.to(device)\n",
    "#     yb = yb.to(device)\n",
    "#     # forward pass into Transformer / DPFT model...\n",
    "#     break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d172f972",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-12T15:46:41.102187Z",
     "iopub.status.busy": "2025-11-12T15:46:41.102055Z",
     "iopub.status.idle": "2025-11-12T15:46:41.115635Z",
     "shell.execute_reply": "2025-11-12T15:46:41.115146Z"
    }
   },
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Phase 4: Losses & Metrics\n",
    "# =========================\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import itertools\n",
    "from typing import List, Tuple, Dict\n",
    "\n",
    "# ---------- helpers ----------\n",
    "def _to_list(x):\n",
    "    # accept list[Tensor] or tuple[...] or Tensor (S stacked on dim=1)\n",
    "    if isinstance(x, (list, tuple)):\n",
    "        return list(x)\n",
    "    if torch.is_tensor(x):\n",
    "        # Expect shape (B, 2, S, 1, T) or (B, 2, S, C, T). Split S.\n",
    "        assert x.dim() >= 5, f\"Stacked outputs must be (B,2,S,*,T), got {x.shape}\"\n",
    "        return [x[:, :, s] for s in range(x.size(2))]\n",
    "    raise TypeError(\"Unsupported outputs/targets container\")\n",
    "\n",
    "def _flatten_wave(x: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    x: (B, 2, C, T)\n",
    "    Returns unchanged; losses handle general (C,T).\n",
    "    \"\"\"\n",
    "    assert x.dim() == 4, f\"Expected (B,2,C,T), got {x.shape}\"\n",
    "    return x\n",
    "\n",
    "\n",
    "# ---------- losses ----------\n",
    "def complex_mse(pred: torch.Tensor, target: torch.Tensor, reduce: bool=True) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Time-domain complex MSE:\n",
    "      MSE = mean( (pr-tr)^2 + (pi-ti)^2 ) over all dims except batch\n",
    "    pred/target: (B, 2, C, T)\n",
    "    \"\"\"\n",
    "    diff = pred - target\n",
    "    loss = (diff ** 2).sum(dim=1)  # sum real+imag -> (B, C, T)\n",
    "    loss = loss.mean(dim=(1,2))    # mean over C,T -> (B,)\n",
    "    return loss.mean() if reduce else loss\n",
    "\n",
    "\n",
    "def si_snr_real(pred_r: torch.Tensor, target_r: torch.Tensor, eps: float=1e-8) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Scale-Invariant SNR for a real waveform.\n",
    "    pred_r/target_r: (B, C, T) -> returns (B,)\n",
    "    \"\"\"\n",
    "    # zero-mean\n",
    "    x = pred_r - pred_r.mean(dim=-1, keepdim=True)\n",
    "    s = target_r - target_r.mean(dim=-1, keepdim=True)\n",
    "    # projection of x on s\n",
    "    s_pow = (s ** 2).sum(dim=-1, keepdim=True) + eps    # (B,C,1)\n",
    "    proj = ((x * s).sum(dim=-1, keepdim=True) / s_pow) * s\n",
    "    e = x - proj\n",
    "    si_snr = 10 * torch.log10((proj.pow(2).sum(dim=-1) + eps) / (e.pow(2).sum(dim=-1) + eps))  # (B,C)\n",
    "    return si_snr.mean(dim=1)  # (B,)\n",
    "\n",
    "\n",
    "def si_snr_complex(pred: torch.Tensor, target: torch.Tensor, eps: float=1e-8, reduce: bool=True) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Complex SI-SNR by averaging SI-SNR of real and imag parts.\n",
    "    pred/target: (B, 2, C, T)\n",
    "    Returns scalar (mean over batch) by default.\n",
    "    \"\"\"\n",
    "    pr, pi = pred[:,0], pred[:,1]     # (B,C,T)\n",
    "    tr, ti = target[:,0], target[:,1]\n",
    "    r = si_snr_real(pr, tr, eps=eps)  # (B,)\n",
    "    i = si_snr_real(pi, ti, eps=eps)  # (B,)\n",
    "    out = 0.5 * (r + i)               # (B,)\n",
    "    return out.mean() if reduce else out\n",
    "\n",
    "\n",
    "# ---------- PIT wrapper ----------\n",
    "def pit_permutation_min(\n",
    "    preds: List[torch.Tensor],\n",
    "    targets: List[torch.Tensor],\n",
    "    pair_loss_fn,  # function(pred, target, reduce=False) -> (B,)\n",
    ") -> Tuple[torch.Tensor, List[int], Dict[str, torch.Tensor]]:\n",
    "    \"\"\"\n",
    "    Compute PIT over all S! permutations and choose ONE permutation\n",
    "    for the whole batch: the one with the lowest mean loss.\n",
    "    Returns:\n",
    "      loss_mean (scalar), best_perm (list[int]), extras {'per_batch': (B,)}\n",
    "    \"\"\"\n",
    "    S = len(targets)\n",
    "    B = targets[0].size(0)\n",
    "    device = targets[0].device\n",
    "\n",
    "    # pair[i,j] = loss between preds[i] and targets[j], shape (B,)\n",
    "    pair = torch.stack(\n",
    "        [torch.stack([pair_loss_fn(p, t, reduce=False) for t in targets], dim=1) for p in preds],\n",
    "        dim=0\n",
    "    )  # (S, S, B)\n",
    "\n",
    "    best_mean = None\n",
    "    best_perm = None\n",
    "    best_per_batch = None\n",
    "\n",
    "    for perm in itertools.permutations(range(S)):\n",
    "        # sum losses across matched pairs for this permutation, still per-batch\n",
    "        per_batch = torch.stack([pair[i, perm[i]] for i in range(S)], dim=0).sum(dim=0)  # (B,)\n",
    "        mean_loss = per_batch.mean()\n",
    "\n",
    "        if (best_mean is None) or (mean_loss < best_mean):\n",
    "            best_mean = mean_loss\n",
    "            best_perm = list(perm)\n",
    "            best_per_batch = per_batch\n",
    "\n",
    "    return best_mean, best_perm, {\"per_batch\": best_per_batch}\n",
    "\n",
    "\n",
    "class CTDCRNLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Joint PIT on the combined loss:\n",
    "      total = w_mse * MSE + w_sisnr * (-SI-SNR)\n",
    "    PIT is done once on the total, ensuring same permutation for both terms.\n",
    "    \"\"\"\n",
    "    def __init__(self, w_mse: float = 1.0, w_sisnr: float = 0.0):\n",
    "        super().__init__()\n",
    "        self.w_mse = w_mse\n",
    "        self.w_sisnr = w_sisnr\n",
    "\n",
    "    def forward(self, outs: List[torch.Tensor], tgts: List[torch.Tensor]) -> Tuple[torch.Tensor, Dict]:\n",
    "        outs = [_flatten_wave(o) for o in _to_list(outs)]\n",
    "        tgts = [_flatten_wave(t) for t in _to_list(tgts)]\n",
    "        S = len(tgts)\n",
    "\n",
    "        # ---------- Combined loss for each permutation ----------\n",
    "        def pair_total(p, t, reduce=False):\n",
    "            mse = complex_mse(p, t, reduce=False)\n",
    "            neg_si = -si_snr_complex(p, t, reduce=False)\n",
    "            return self.w_mse * mse + self.w_sisnr * neg_si  # (B,)\n",
    "\n",
    "        total, best_perm, info = pit_permutation_min(outs, tgts, pair_total)\n",
    "\n",
    "        # ---------- Recompute components under best permutation ----------\n",
    "        tgts_perm = [tgts[j] for j in best_perm]\n",
    "        mse_vals, negsi_vals = [], []\n",
    "        for i in range(S):\n",
    "            mse_i = complex_mse(outs[i], tgts_perm[i], reduce=False)\n",
    "            neg_i = -si_snr_complex(outs[i], tgts_perm[i], reduce=False)\n",
    "            mse_vals.append(mse_i)\n",
    "            negsi_vals.append(neg_i)\n",
    "\n",
    "        mse_loss = torch.stack(mse_vals).sum(dim=0).mean()\n",
    "        negsi_loss = torch.stack(negsi_vals).sum(dim=0).mean()\n",
    "\n",
    "        logs = {\n",
    "            \"mse\": mse_loss.detach(),\n",
    "            \"neg_sisnr\": negsi_loss.detach(),\n",
    "            \"si_snr_db\": (-negsi_loss).detach(),  # for easy monitoring\n",
    "            \"total\": total.detach(),\n",
    "            \"pit_perm\": torch.tensor(best_perm)\n",
    "        }\n",
    "        return total, logs\n",
    "\n",
    "\n",
    "# ---------- metrics ----------\n",
    "@torch.no_grad()\n",
    "def corr_phase_invariant_batched(x: torch.Tensor, y: torch.Tensor, eps: float = 1e-8) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Phase-invariant complex correlation magnitude in [0,1], per batch.\n",
    "    x,y: (B,2,1,T) or (B,2,C,T) -> reduces over C and T.\n",
    "    \"\"\"\n",
    "    # collapse C by mean if present\n",
    "    if x.dim() == 4 and x.size(2) > 1:\n",
    "        x = x.mean(dim=2, keepdim=True)\n",
    "        y = y.mean(dim=2, keepdim=True)\n",
    "\n",
    "    xr = x[:, 0, 0, :] - x[:, 0, 0, :].mean(dim=-1, keepdim=True)  # (B,T)\n",
    "    xi = x[:, 1, 0, :] - x[:, 1, 0, :].mean(dim=-1, keepdim=True)\n",
    "    yr = y[:, 0, 0, :] - y[:, 0, 0, :].mean(dim=-1, keepdim=True)\n",
    "    yi = y[:, 1, 0, :] - y[:, 1, 0, :].mean(dim=-1, keepdim=True)\n",
    "\n",
    "    # complex inner product <x,y>\n",
    "    re = (xr * yr + xi * yi).sum(dim=-1)          # (B,)\n",
    "    im = (xi * yr - xr * yi).sum(dim=-1)          # (B,)\n",
    "    num = torch.sqrt(re ** 2 + im ** 2)           # |<x,y>| (B,)\n",
    "\n",
    "    xn = torch.sqrt((xr ** 2 + xi ** 2).sum(dim=-1) + eps)\n",
    "    yn = torch.sqrt((yr ** 2 + yi ** 2).sum(dim=-1) + eps)\n",
    "    r = num / (xn * yn + eps)                     # (B,) in [0,1]\n",
    "    return r\n",
    "\n",
    "\n",
    "# @torch.no_grad()\n",
    "# def corr_phase_inv_PIT(outs: List[torch.Tensor], targets: List[torch.Tensor]) -> torch.Tensor:\n",
    "#     \"\"\"\n",
    "#     S=2 PIT-aware phase-invariant correlation. Returns scalar mean in [0,1].\n",
    "#     outs/targets: list of two tensors, each (B,2,1,T) or (B,2,C,T).\n",
    "#     \"\"\"\n",
    "#     assert len(outs) == 2 and len(targets) == 2, \"This helper assumes S=2.\"\n",
    "#     r00 = corr_phase_invariant_batched(outs[0], targets[0])\n",
    "#     r11 = corr_phase_invariant_batched(outs[1], targets[1])\n",
    "#     r01 = corr_phase_invariant_batched(outs[0], targets[1])\n",
    "#     r10 = corr_phase_invariant_batched(outs[1], targets[0])\n",
    "#     r_best = torch.maximum(r00 + r11, r01 + r10) * 0.5  # best pairing, averaged\n",
    "#     return r_best.mean()\n",
    "\n",
    "\n",
    "# @torch.no_grad()\n",
    "# def pearson_r_paper(pred: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
    "#     \"\"\"\n",
    "#     Eq. (22) Pearson correlation on REAL waveforms (for final reporting).\n",
    "#     pred/target: (B,2,1,T) or (B,2,C,T) -> uses real lane only, reduces over C.\n",
    "#     Returns scalar mean in [-1,1].\n",
    "#     \"\"\"\n",
    "#     # collapse C by mean if present\n",
    "#     if pred.dim() == 4 and pred.size(2) > 1:\n",
    "#         pred = pred.mean(dim=2, keepdim=True)\n",
    "#         target = target.mean(dim=2, keepdim=True)\n",
    "\n",
    "#     a = pred[:, 0, 0, :]  # real part (B,T)\n",
    "#     b = target[:, 0, 0, :]\n",
    "#     a = a - a.mean(dim=-1, keepdim=True)\n",
    "#     b = b - b.mean(dim=-1, keepdim=True)\n",
    "#     num = (a * b).sum(dim=-1)\n",
    "#     den = (a.pow(2).sum(dim=-1).sqrt() * b.pow(2).sum(dim=-1).sqrt() + 1e-8)\n",
    "#     return (num / den).mean()\n",
    "\n",
    "\n",
    "def si_snr_improvement(mix: torch.Tensor, pred: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\" SI-SNR(pred,target) - SI-SNR(mix,target); tensors (B,2,C,T) \"\"\"\n",
    "    return si_snr_complex(pred, target) - si_snr_complex(mix, target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76467901",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-12T15:46:41.116900Z",
     "iopub.status.busy": "2025-11-12T15:46:41.116764Z",
     "iopub.status.idle": "2025-11-12T15:46:41.118790Z",
     "shell.execute_reply": "2025-11-12T15:46:41.118297Z"
    }
   },
   "outputs": [],
   "source": [
    "# import importlib, dataset\n",
    "# importlib.reload(dataset)\n",
    "# from dataset import build_dataloader\n",
    "\n",
    "# data_path = \"/home/bss/data/GOLD_XYZ_OSC.0001_1024.hdf5\"\n",
    "\n",
    "# train_loader = build_dataloader(\n",
    "#     data_path,\n",
    "#     batch_size=256, num_workers=30, prefetch_factor=8,\n",
    "#     persistent_workers=True, pin_memory=True,\n",
    "#     filter_mods=[\"BPSK\",\"QPSK\"],\n",
    "#     snr_values=list(range(-5,26,5)),    # -5..25 dB at 5 dB steps\n",
    "#     sir_db_range=(-3.0, 3.0),\n",
    "#     awgn_snr_db_range=(20,40),\n",
    "#     normalize_frames=True,\n",
    "#     return_meta=False,\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b396b8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-12T15:46:41.119856Z",
     "iopub.status.busy": "2025-11-12T15:46:41.119734Z",
     "iopub.status.idle": "2025-11-12T15:46:41.121916Z",
     "shell.execute_reply": "2025-11-12T15:46:41.121478Z"
    }
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# @torch.no_grad()\n",
    "# def rho_np(a: np.ndarray, b: np.ndarray) -> float:\n",
    "#     \"\"\"Scalar Pearson correlation using paper Eq. (22).\"\"\"\n",
    "#     a = a - a.mean()\n",
    "#     b = b - b.mean()\n",
    "#     den = (np.linalg.norm(a) * np.linalg.norm(b) + 1e-12)\n",
    "#     return float((a @ b) / den) if den > 0 else 0.0\n",
    "\n",
    "# @torch.no_grad()\n",
    "# def pearson_rho_batch(est_iq: torch.Tensor, tgt_iq: torch.Tensor) -> float:\n",
    "#     \"\"\"\n",
    "#     Paper Pearson ρ averaged over batch, real/imag separately, then mean.\n",
    "#     est_iq/tgt_iq: (B,2,T) or (B,2,1,T)\n",
    "#     \"\"\"\n",
    "#     est = est_iq.detach().cpu().numpy()\n",
    "#     tgt = tgt_iq.detach().cpu().numpy()\n",
    "#     if est.ndim == 4:  # (B,2,1,T)\n",
    "#         est = est.squeeze(2)\n",
    "#         tgt = tgt.squeeze(2)\n",
    "#     B = est.shape[0]\n",
    "#     vals = []\n",
    "#     for i in range(B):\n",
    "#         r_r = rho_np(est[i, 0], tgt[i, 0])\n",
    "#         r_i = rho_np(est[i, 1], tgt[i, 1])\n",
    "#         vals.append(0.5 * (r_r + r_i))\n",
    "#     return float(np.mean(vals)) if vals else 0.0\n",
    "\n",
    "# @torch.no_grad()\n",
    "# def pearson_rho_PIT(outs, tgts) -> float:\n",
    "#     \"\"\"Apply PIT to the above rho.\"\"\"\n",
    "#     r00 = pearson_rho_batch(outs[0], tgts[0])\n",
    "#     r11 = pearson_rho_batch(outs[1], tgts[1])\n",
    "#     r01 = pearson_rho_batch(outs[0], tgts[1])\n",
    "#     r10 = pearson_rho_batch(outs[1], tgts[0])\n",
    "#     return max((r00 + r11) / 2, (r01 + r10) / 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8db8593",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-12T15:46:41.123026Z",
     "iopub.status.busy": "2025-11-12T15:46:41.122909Z",
     "iopub.status.idle": "2025-11-12T15:46:41.125791Z",
     "shell.execute_reply": "2025-11-12T15:46:41.125339Z"
    }
   },
   "outputs": [],
   "source": [
    "# @torch.no_grad()\n",
    "# def project_estimate_to_target(a: torch.Tensor, s: torch.Tensor, eps: float = 1e-8):\n",
    "#     \"\"\"\n",
    "#     Project estimate `a` onto `s` along time axis.\n",
    "#     a, s: (B, C, T) real tensors. Returns projected a_proj: (B, C, T)\n",
    "#     \"\"\"\n",
    "#     s_pow = (s ** 2).sum(dim=-1, keepdim=True) + eps  # (B, C, 1)\n",
    "#     dot = (a * s).sum(dim=-1, keepdim=True)  # (B, C, 1)\n",
    "#     a_proj = (dot / s_pow) * s\n",
    "#     return a_proj\n",
    "\n",
    "# @torch.no_grad()\n",
    "# def pearson_real_proj(a: torch.Tensor, b: torch.Tensor, eps: float = 1e-8):\n",
    "#     \"\"\"\n",
    "#     Pearson correlation between real waveforms a,b after projection of a onto b.\n",
    "#     a,b: (B, C, T) real\n",
    "#     Returns (B, C) per-sample per-channel correlations.\n",
    "#     \"\"\"\n",
    "#     # center\n",
    "#     a_mean = a.mean(dim=-1, keepdim=True)\n",
    "#     b_mean = b.mean(dim=-1, keepdim=True)\n",
    "#     a0 = a - a_mean\n",
    "#     b0 = b - b_mean\n",
    "\n",
    "#     # project a onto b (removes scale)\n",
    "#     a_proj = project_estimate_to_target(a0, b0, eps=eps)\n",
    "\n",
    "#     am = a_proj - a_proj.mean(dim=-1, keepdim=True)\n",
    "#     bm = b0    # already zero-mean\n",
    "#     cov = (am * bm).sum(dim=-1)  # (B, C)\n",
    "#     a_std = torch.sqrt((am ** 2).sum(dim=-1) + eps)\n",
    "#     b_std = torch.sqrt((bm ** 2).sum(dim=-1) + eps)\n",
    "#     rho = cov / (a_std * b_std + eps)  # (B, C)\n",
    "#     return rho\n",
    "\n",
    "# @torch.no_grad()\n",
    "# def pearson_r_paper_PIT(outs: List[torch.Tensor], targets: List[torch.Tensor]) -> torch.Tensor:\n",
    "#     \"\"\"\n",
    "#     PIT-aware Pearson for Eq.(22) used in paper reporting.\n",
    "#     outs/targets: list length S (S=2), each tensor (B,2,1,T) or (B,2,C,T).\n",
    "#     Uses ONLY real lane (index 0), averages over channels and batch, and applies the\n",
    "#     permutation (PIT) that *maximizes* sum of per-source correlations.\n",
    "#     Returns scalar mean in [-1,1].\n",
    "#     \"\"\"\n",
    "#     assert len(outs) == len(targets) == 2, \"Only S=2 supported here (matches your config).\"\n",
    "\n",
    "#     # helper to get real lane (B,C,T) from (B,2,1,T) or (B,2,C,T)\n",
    "#     def real_lane(x):\n",
    "#         if x.dim() == 4 and x.size(2) > 1:\n",
    "#             x = x.mean(dim=2)  # (B,2,T) -> we want (B,T) per lane; but keep consistent below\n",
    "#             # after mean, shape is (B,2,T)\n",
    "#             return x[:, 0, :]  # (B, T)\n",
    "#         elif x.dim() == 4 and x.size(2) == 1:\n",
    "#             return x[:, 0, 0, :]  # (B, T)\n",
    "#         elif x.dim() == 3 and x.size(1) == 2:\n",
    "#             return x[:, 0, :]     # (B, T)\n",
    "#         else:\n",
    "#             raise ValueError(f\"Unexpected tensor shape in pearson_r_paper_PIT: {x.shape}\")\n",
    "\n",
    "#     # extract real lanes and ensure shape (B, 1, T) to reuse pearson_real_proj which expects (B,C,T)\n",
    "#     a0 = real_lane(outs[0]).unsqueeze(1)   # (B,1,T)\n",
    "#     a1 = real_lane(outs[1]).unsqueeze(1)\n",
    "#     t0 = real_lane(targets[0]).unsqueeze(1)\n",
    "#     t1 = real_lane(targets[1]).unsqueeze(1)\n",
    "\n",
    "#     # compute per-source per-sample rho (B, C) — here C==1\n",
    "#     rho00 = pearson_real_proj(a0, t0)  # (B,1)\n",
    "#     rho11 = pearson_real_proj(a1, t1)\n",
    "#     rho01 = pearson_real_proj(a0, t1)\n",
    "#     rho10 = pearson_real_proj(a1, t0)\n",
    "\n",
    "#     # sum per-permutation\n",
    "#     sum_00_11 = (rho00 + rho11).squeeze(1)  # (B,)\n",
    "#     sum_01_10 = (rho01 + rho10).squeeze(1)  # (B,)\n",
    "\n",
    "#     # choose best permutation per sample (max sum)\n",
    "#     choose_first = (sum_00_11 >= sum_01_10).float().unsqueeze(1)  # (B,1)\n",
    "#     # selected per-sample per-channel rhos\n",
    "#     # selected_rho_source0 = where choose_first: rho00 else rho01\n",
    "#     sel_r0 = choose_first * rho00 + (1.0 - choose_first) * rho01  # (B,1)\n",
    "#     sel_r1 = choose_first * rho11 + (1.0 - choose_first) * rho10  # (B,1)\n",
    "\n",
    "#     # now average real+imag? Paper Eq(22) asks real-lane only for r_paper in your code comments.\n",
    "#     # So we average the two selected source correlations and then mean over batch.\n",
    "#     per_sample = 0.5 * (sel_r0.squeeze(1) + sel_r1.squeeze(1))  # (B,)\n",
    "#     return per_sample.mean().item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4163102",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-12T15:46:41.126793Z",
     "iopub.status.busy": "2025-11-12T15:46:41.126680Z",
     "iopub.status.idle": "2025-11-12T15:46:41.131482Z",
     "shell.execute_reply": "2025-11-12T15:46:41.130945Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "@torch.no_grad()\n",
    "def _pearson_1d(a: torch.Tensor, b: torch.Tensor, eps: float = 1e-8) -> torch.Tensor:\n",
    "    # a,b: (B, T) real\n",
    "    a = a - a.mean(dim=-1, keepdim=True)\n",
    "    b = b - b.mean(dim=-1, keepdim=True)\n",
    "    num = (a * b).sum(dim=-1)\n",
    "    den = a.norm(dim=-1) * b.norm(dim=-1) + eps\n",
    "    return num / den  # (B,)\n",
    "\n",
    "@torch.no_grad()\n",
    "def _collapse_channels(x: torch.Tensor) -> torch.Tensor:\n",
    "    # x: (B, C, T) -> (B, T) by averaging across C\n",
    "    return x.mean(dim=1)\n",
    "\n",
    "@torch.no_grad()\n",
    "def pearson_r_paper_PIT_torch(outs, tgts) -> float:\n",
    "    \"\"\"\n",
    "    Paper-accurate Pearson ρ with PIT.\n",
    "    outs/tgts: lists length 2; tensors (B,2,1,T) or (B,2,C,T).\n",
    "    Returns scalar float.\n",
    "    \"\"\"\n",
    "    assert len(outs) == len(tgts) == 2\n",
    "\n",
    "    def lanes(x):  # -> (xr, xi) each (B, T)\n",
    "        if x.dim() == 3:         # (B,2,T)\n",
    "            xr = x[:, 0, :]\n",
    "            xi = x[:, 1, :]\n",
    "        elif x.dim() == 4:       # (B,2,C,T)\n",
    "            xr = _collapse_channels(x[:, 0])  # (B,T)\n",
    "            xi = _collapse_channels(x[:, 1])\n",
    "        else:\n",
    "            raise ValueError(f\"bad shape {tuple(x.shape)}\")\n",
    "        return xr, xi\n",
    "\n",
    "    y0r, y0i = lanes(outs[0]); y1r, y1i = lanes(outs[1])\n",
    "    s0r, s0i = lanes(tgts[0]); s1r, s1i = lanes(tgts[1])\n",
    "\n",
    "    # real & imag Pearson, averaged per lane\n",
    "    r00 = 0.5 * (_pearson_1d(y0r, s0r) + _pearson_1d(y0i, s0i))  # (B,)\n",
    "    r11 = 0.5 * (_pearson_1d(y1r, s1r) + _pearson_1d(y1i, s1i))\n",
    "    r01 = 0.5 * (_pearson_1d(y0r, s1r) + _pearson_1d(y0i, s1i))\n",
    "    r10 = 0.5 * (_pearson_1d(y1r, s0r) + _pearson_1d(y1i, s0i))\n",
    "\n",
    "    best = torch.maximum(r00 + r11, r01 + r10) * 0.5  # choose best pairing, then average two sources\n",
    "    return float(best.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62aac810",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-12T15:46:41.132817Z",
     "iopub.status.busy": "2025-11-12T15:46:41.132695Z",
     "iopub.status.idle": "2025-11-12T15:59:51.513239Z",
     "shell.execute_reply": "2025-11-12T15:59:51.511891Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GOLDMixAWGNDataset] kept 212,992 / 2,555,904 frames (mods=['BPSK', 'QPSK'], SNR_values=None, SNR_range=(-20, 30))\n",
      "[balance_mods] Balanced mods ['BPSK', 'QPSK'] to 106496 samples each (total 212992).\n",
      "[GOLDMixAWGNDataset] kept 212,992 / 2,555,904 frames (mods=['BPSK', 'QPSK'], SNR_values=None, SNR_range=(-20, 30))\n",
      "\n",
      "Split summary:\n",
      "  Train samples : 170,393\n",
      "  Val samples   : 21,299\n",
      "  Test samples  : 21,300\n",
      "\n",
      "=== CTDCRN Training Setup ===\n",
      " Save dir     : /home/bss/ctdcrn_runs/exp70\n",
      " Epochs       : 1\n",
      " Batch size   : 256\n",
      " Steps/epoch  : 666\n",
      " Model params : 378,308\n",
      "==============================\n",
      "\n",
      "Epoch |   LR     |   Train(avg)               |   Val(full-epoch)        |  t_train   t_val\n",
      "      |          |    loss      MSE   -SI     |    loss     r_paper      |                \n",
      "--> Epoch 1: MSE disabled. Optimizing SI-SNR only.\n",
      "[loss-weights] epoch=1  w_mse=0.000  w_sisnr=1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2710697/91120085.py:369: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler(enabled=use_amp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[DATA CHECK] Mean Diff (Mix - S1 - S2): 0.383773\n",
      "CRITICAL WARNING: Mixture does not equal sum of sources!\n",
      "Check normalize_frames=True in dataset.py\n",
      "\n",
      "  ep01 step 00100/666 avg_train_loss=19.4012  lr=1.00e-03\n",
      "\n",
      "  ep01 step 00200/666 avg_train_loss=13.1248  lr=1.00e-03\n",
      "\n",
      "  ep01 step 00300/666 avg_train_loss=10.5100  lr=1.00e-03\n",
      "\n",
      "  ep01 step 00400/666 avg_train_loss=9.2383  lr=1.00e-03\n",
      "\n",
      "  ep01 step 00500/666 avg_train_loss=8.4025  lr=1.00e-03\n",
      "\n",
      "  ep01 step 00600/666 avg_train_loss=7.8730  lr=1.00e-03\n",
      "  [PIT perms] epoch=1  [0,1]: 319 (47.90%), [1,0]: 347 (52.10%)\n",
      "    1 | 1.0e-03 |    7.5296  5564.7898 8.4885 |    5.4226    0.0211 |     95.5s   19.0s\n",
      "  ↳ New best @ epoch 1: val_loss=5.4226, val_r_paper=0.0211 (saved best.pt)\n",
      "\n",
      "Saved training history to: ctdcrn_runs/exp70/history.json\n",
      "\n",
      "[Test @ end] loss=1.6717  r_paper=0.0224  time=10.5s\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# Phase 5: Training / Evaluation (Deterministic Split)\n",
    "# ===============================\n",
    "import os, time, json, random\n",
    "from pathlib import Path\n",
    "from typing import Dict, List\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import amp\n",
    "from torch.cuda.amp import GradScaler\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---- your model/loss/dataset imports ----\n",
    "from dataset import GOLDMixAWGNDataset, collate_mix\n",
    "# CTDCRN, CTDCRNLoss assumed importable or defined\n",
    "\n",
    "# ---------------- config ----------------\n",
    "TWO_MODS = [\"BPSK\", \"QPSK\"]  # exactly two mods\n",
    "TRAINVAL_SNR_RANGE = (-5, 25)  # AWGN SNR ~ Uniform(-5, 25) dB\n",
    "TEST_SNR = 20  # fixed/easy SNR for test\n",
    "\n",
    "\n",
    "class Cfg:\n",
    "    root_dir = Path(\"./ctdcrn_runs\")\n",
    "    save_dir = None\n",
    "    epochs = 1\n",
    "    lr = 1e-3\n",
    "    weight_decay = 1e-4\n",
    "    grad_clip = 5.0\n",
    "    amp = True\n",
    "    compile_model = True   # PyTorch ≥ 2.3\n",
    "    log_interval = 100     # steps\n",
    "    n_sources = 2\n",
    "    batch_size = 256\n",
    "    \n",
    "    # NEW: Paths to deterministic split files\n",
    "    split_dir = Path(\".\") # Current directory, or change to where .npy files are\n",
    "    train_idx_file = \"train_indices.npy\"\n",
    "    val_idx_file = \"val_indices.npy\"\n",
    "    test_idx_file = \"test_indices.npy\"\n",
    "\n",
    "\n",
    "cfg = Cfg()\n",
    "\n",
    "# --- ENV overrides ---\n",
    "def _env_bool(k, default=False):\n",
    "    v = os.getenv(k)\n",
    "    return default if v is None else v.lower() in (\"1\", \"true\", \"yes\", \"y\", \"on\")\n",
    "\n",
    "mods_env = os.getenv(\"MODS\")\n",
    "if mods_env:\n",
    "    toks = [t for t in mods_env.replace(\",\", \" \").split() if t]\n",
    "    TWO_MODS = toks\n",
    "\n",
    "cfg.epochs = int(os.getenv(\"EPOCHS\", cfg.epochs))\n",
    "cfg.batch_size = int(os.getenv(\"BATCH_SIZE\", cfg.batch_size))\n",
    "cfg.lr = float(os.getenv(\"LR\", cfg.lr))\n",
    "cfg.weight_decay = float(os.getenv(\"WEIGHT_DECAY\", cfg.weight_decay))\n",
    "cfg.grad_clip = float(os.getenv(\"GRAD_CLIP\", cfg.grad_clip))\n",
    "cfg.amp = _env_bool(\"AMP\", cfg.amp)\n",
    "cfg.compile_model = _env_bool(\"COMPILE\", cfg.compile_model)\n",
    "\n",
    "MODEL_CHANNELS = int(os.getenv(\"MODEL_CHANNELS\", 32))\n",
    "MODEL_CHE_MID = int(os.getenv(\"MODEL_CHE_MID\", 64))\n",
    "MODEL_N_CDCM_A = int(os.getenv(\"MODEL_N_CDCM_A\", 4))\n",
    "MODEL_N_CDCM_B = int(os.getenv(\"MODEL_N_CDCM_B\", 4))\n",
    "SLOPE = float(os.getenv(\"SLOPE\", \"0.01\"))\n",
    "\n",
    "if os.getenv(\"TRAINVAL_SNR\"):\n",
    "    a, b = [float(x) for x in os.getenv(\"TRAINVAL_SNR\").split(\",\")]\n",
    "    TRAINVAL_SNR_RANGE = (a, b)\n",
    "if os.getenv(\"TEST_SNR\"):\n",
    "    TEST_SNR = float(os.getenv(\"TEST_SNR\"))\n",
    "\n",
    "SUBSAMPLE_FRAC = float(os.getenv(\"SUBSAMPLE_FRAC\", \"1.0\"))\n",
    "SUBSAMPLE_SEED = int(os.getenv(\"SUBSAMPLE_SEED\", \"1337\"))\n",
    "BALANCE_MODS = True \n",
    "\n",
    "# --- Reproducibility ---\n",
    "def set_seed(seed=1337):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(1337)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.set_float32_matmul_precision(\"high\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "amp_dev = \"cuda\" if device.type == \"cuda\" else \"cpu\"\n",
    "use_amp = cfg.amp and (device.type == \"cuda\")\n",
    "\n",
    "# --------- Experiment Setup ----------\n",
    "def allocate_exp_dir(root: Path, prefer: str = \"exp1\") -> Path:\n",
    "    root.mkdir(parents=True, exist_ok=True)\n",
    "    d = root / prefer\n",
    "    if not d.exists():\n",
    "        d.mkdir(parents=True, exist_ok=True)\n",
    "        return d\n",
    "    n = 2\n",
    "    while (root / f\"exp{n}\").exists(): n += 1\n",
    "    d = root / f\"exp{n}\"\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "    return d\n",
    "\n",
    "cfg.save_dir = allocate_exp_dir(cfg.root_dir, \"exp1\")\n",
    "\n",
    "with open(cfg.save_dir / \"config.json\", \"w\") as f:\n",
    "    json.dump(vars(cfg) | {\"mods\": TWO_MODS}, f, indent=2, default=str)\n",
    "\n",
    "class TeeLogger:\n",
    "    def __init__(self, path: Path):\n",
    "        self.path = path\n",
    "        self.f = open(path, \"a\", buffering=1, encoding=\"utf-8\")\n",
    "    def log(self, msg=\"\"):\n",
    "        print(msg)\n",
    "        try: self.f.write(msg + \"\\n\")\n",
    "        except: pass\n",
    "    def close(self):\n",
    "        try: self.f.close()\n",
    "        except: pass\n",
    "\n",
    "LOG = TeeLogger(cfg.save_dir / \"train.log\")\n",
    "\n",
    "# ---------------- Metrics ----------------\n",
    "@torch.no_grad()\n",
    "def _pearson_1d(a, b, eps=1e-8):\n",
    "    a = a - a.mean(dim=-1, keepdim=True)\n",
    "    b = b - b.mean(dim=-1, keepdim=True)\n",
    "    return (a * b).sum(dim=-1) / (a.norm(dim=-1) * b.norm(dim=-1) + eps)\n",
    "\n",
    "@torch.no_grad()\n",
    "def pearson_r_paper_PIT_torch(outs, tgts):\n",
    "    def lanes(x):\n",
    "        return (x[:, 0, :], x[:, 1, :]) if x.dim() == 3 else (x[:, 0].mean(1), x[:, 1].mean(1))\n",
    "    \n",
    "    y0r, y0i = lanes(outs[0])\n",
    "    y1r, y1i = lanes(outs[1])\n",
    "    s0r, s0i = lanes(tgts[0])\n",
    "    s1r, s1i = lanes(tgts[1])\n",
    "\n",
    "    r00 = 0.5 * (_pearson_1d(y0r, s0r) + _pearson_1d(y0i, s0i))\n",
    "    r11 = 0.5 * (_pearson_1d(y1r, s1r) + _pearson_1d(y1i, s1i))\n",
    "    r01 = 0.5 * (_pearson_1d(y0r, s1r) + _pearson_1d(y0i, s1i))\n",
    "    r10 = 0.5 * (_pearson_1d(y1r, s0r) + _pearson_1d(y1i, s0i))\n",
    "\n",
    "    return float(torch.maximum(r00 + r11, r01 + r10).mean() * 0.5)\n",
    "\n",
    "# =========================================================\n",
    "#  DATA LOADING: DETERMINISTIC SPLIT LOGIC (Method 3)\n",
    "# =========================================================\n",
    "data_path = \"/home/bss/data/GOLD_XYZ_OSC.0001_1024.hdf5\"\n",
    "\n",
    "# Check if deterministic split files exist\n",
    "has_split_files = (\n",
    "    (cfg.split_dir / cfg.train_idx_file).exists() and \n",
    "    (cfg.split_dir / cfg.val_idx_file).exists() and \n",
    "    (cfg.split_dir / cfg.test_idx_file).exists()\n",
    ")\n",
    "\n",
    "# NOTE: If using global HDF5 indices (from Step 1 of the solution), \n",
    "# we must NOT filter mods inside the dataset, or the indices will mismatch.\n",
    "# We assume the indices in .npy files already point to the correct rows (BPSK/QPSK).\n",
    "filter_mods_arg = None if has_split_files else TWO_MODS\n",
    "if has_split_files:\n",
    "    LOG.log(f\"[Setup] Deterministic split found! Loading raw indices and disabling internal filters.\")\n",
    "\n",
    "base_ds = GOLDMixAWGNDataset(\n",
    "    h5_path=data_path,\n",
    "    filter_mods=filter_mods_arg,  # Pass None if using global indices\n",
    "    snr_range=(-20, 30),\n",
    "    sir_db_range=(-3.0, 3.0),\n",
    "    awgn_snr_db_range=TRAINVAL_SNR_RANGE,\n",
    "    normalize_frames=True,\n",
    "    return_meta=False,\n",
    ")\n",
    "\n",
    "# 1. Deterministic Split (Priority)\n",
    "if has_split_files:\n",
    "    LOG.log(\"[Split] Loading pre-computed indices from disk...\")\n",
    "    idx_train = np.load(cfg.split_dir / cfg.train_idx_file)\n",
    "    idx_val   = np.load(cfg.split_dir / cfg.val_idx_file)\n",
    "    idx_test  = np.load(cfg.split_dir / cfg.test_idx_file)\n",
    "    \n",
    "# 2. Dynamic/Random Split (Fallback)\n",
    "else:\n",
    "    LOG.log(\"[Split] No index files found. Falling back to RANDOM split (Method 1).\")\n",
    "    \n",
    "    # --- Subsample / Balance Mods logic (Only run this if NOT using split files) ---\n",
    "    if SUBSAMPLE_FRAC < 1.0 or BALANCE_MODS:\n",
    "        import h5py\n",
    "        with h5py.File(data_path, \"r\") as f:\n",
    "            Y = f[\"Y\"][:]\n",
    "            Z = f[\"Z\"][:]\n",
    "\n",
    "        snr_int = np.asarray(Z, dtype=np.int16).reshape(-1)\n",
    "        mod_idx = Y.argmax(axis=1).reshape(-1)\n",
    "        \n",
    "        # ... (Assuming standard mod list logic here) ...\n",
    "        # (Simplified for brevity, same as original logic)\n",
    "        valid = np.asarray(base_ds.valid_idx, dtype=np.int64) if hasattr(base_ds, 'valid_idx') else np.arange(len(Y))\n",
    "        # Logic to pick indices...\n",
    "        # For simplicity in this edited block, we assume base_ds is already subsampled \n",
    "        # via Subset if this block runs.\n",
    "        pass # (Existing complex logic retained if needed, but skipped for Method 3)\n",
    "\n",
    "    N_total = len(base_ds)\n",
    "    idxs = np.arange(N_total)\n",
    "    np.random.shuffle(idxs)\n",
    "    n_train = int(0.8 * N_total)\n",
    "    n_val = int(0.1 * N_total)\n",
    "    \n",
    "    idx_train = idxs[:n_train]\n",
    "    idx_val = idxs[n_train:n_train + n_val]\n",
    "    idx_test = idxs[n_train + n_val:]\n",
    "\n",
    "# Create final Subsets\n",
    "train_ds = Subset(base_ds, idx_train)\n",
    "val_ds = Subset(base_ds, idx_val)\n",
    "test_ds = Subset(base_ds, idx_test) # Note: Using base_ds for test here to ensure consistency if using global indices\n",
    "\n",
    "# Define Loaders\n",
    "def make_loader(ds, batch_size=cfg.batch_size, shuffle=True):\n",
    "    return DataLoader(\n",
    "        ds, batch_size=batch_size, \n",
    "        num_workers=4, prefetch_factor=4, persistent_workers=True, pin_memory=True,\n",
    "        collate_fn=collate_mix, shuffle=shuffle\n",
    "    )\n",
    "\n",
    "train_loader = make_loader(train_ds, shuffle=True)\n",
    "val_loader = make_loader(val_ds, shuffle=False)\n",
    "test_loader = make_loader(test_ds, shuffle=False)\n",
    "\n",
    "# ---------------- Model Init ----------------\n",
    "model = CTDCRN(\n",
    "    channels=MODEL_CHANNELS, che_mid=MODEL_CHE_MID, ksize=3,\n",
    "    n_src=cfg.n_sources, n_cdcm_a=MODEL_N_CDCM_A, n_cdcm_b=MODEL_N_CDCM_B, slope=SLOPE\n",
    ").to(device)\n",
    "\n",
    "if cfg.compile_model:\n",
    "    try: model = torch.compile(model)\n",
    "    except Exception as e: LOG.log(f\"compile skipped: {e}\")\n",
    "\n",
    "criterion = CTDCRNLoss(w_mse=1.0, w_sisnr=0.5)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=cfg.lr, weight_decay=cfg.weight_decay)\n",
    "scaler = GradScaler(enabled=use_amp)\n",
    "\n",
    "# ---------------- Helper Functions ----------------\n",
    "def epoch_header_row():\n",
    "    return \"Epoch |  LR     |  Train(avg)             |  Val(full-epoch)        |  t_train   t_val\"\n",
    "\n",
    "def epoch_row(epoch, lr, tr, va):\n",
    "    return (f\"{epoch:>5d} | {lr:7.1e} |\"\n",
    "            f\"  {tr['loss']:8.4f}  {tr.get('mse',0):7.4f} {tr.get('neg_sisnr',0):6.4f} |\"\n",
    "            f\"  {va['val_loss']:8.4f}  {va['val_r_paper']:8.4f} |\"\n",
    "            f\"  {tr['time_s']:7.1f}s {va['time_s']:6.1f}s\")\n",
    "\n",
    "def move_batch(xb, yb):\n",
    "    return xb.to(device, non_blocking=True), [t.to(device, non_blocking=True) for t in yb]\n",
    "\n",
    "def save_ckpt(path, epoch, model, opt, scaler, best):\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    torch.save({\"epoch\": epoch, \"model\": model.state_dict(), \"opt\": opt.state_dict(), \"scaler\": scaler.state_dict(), \"best\": best}, str(path))\n",
    "\n",
    "# ---------------- Train Loop ----------------\n",
    "def train_one_epoch(epoch):\n",
    "    model.train()\n",
    "    t0 = time.time()\n",
    "    logs_accum = {\"loss\": 0.0, \"mse\": 0.0, \"neg_sisnr\": 0.0}\n",
    "    \n",
    "    for step, (xb_in, yb_in) in enumerate(train_loader, start=1):\n",
    "        xb, yb = move_batch(xb_in, yb_in)\n",
    "        \n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        with amp.autocast(device_type=amp_dev, enabled=use_amp):\n",
    "            outs = model(xb)\n",
    "            loss, logs = criterion(outs, yb)\n",
    "        \n",
    "        scaler.scale(loss).backward()\n",
    "        if cfg.grad_clip:\n",
    "            scaler.unscale_(optimizer)\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), cfg.grad_clip)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        logs_accum[\"loss\"] += float(logs[\"total\"])\n",
    "        logs_accum[\"mse\"] += float(logs[\"mse\"])\n",
    "        logs_accum[\"neg_sisnr\"] += float(logs[\"neg_sisnr\"])\n",
    "\n",
    "        if step % cfg.log_interval == 0:\n",
    "            LOG.log(f\"  ep{epoch:02d} step {step:05d} avg_loss={logs_accum['loss']/step:.4f}\")\n",
    "\n",
    "    n = max(1, step)\n",
    "    for k in logs_accum: logs_accum[k] /= n\n",
    "    logs_accum[\"time_s\"] = time.time() - t0\n",
    "    return logs_accum\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(loader):\n",
    "    model.eval()\n",
    "    t0 = time.time()\n",
    "    loss_sum, r_paper_sum, n = 0.0, 0.0, 0\n",
    "    for xb, yb in loader:\n",
    "        xb, yb = move_batch(xb, yb)\n",
    "        with amp.autocast(device_type=amp_dev, enabled=use_amp):\n",
    "            outs = model(xb)\n",
    "            loss, _ = criterion(outs, yb)\n",
    "        loss_sum += float(loss)\n",
    "        r_paper_sum += pearson_r_paper_PIT_torch(outs, yb)\n",
    "        n += 1\n",
    "    n = max(1, n)\n",
    "    return {\"val_loss\": loss_sum/n, \"val_r_paper\": r_paper_sum/n, \"time_s\": time.time()-t0}\n",
    "\n",
    "# ---------------- Main Execution ----------------\n",
    "LOG.log(f\"\\nSplit summary (Loaded from file: {has_split_files}):\")\n",
    "LOG.log(f\"  Train: {len(train_ds):,}, Val: {len(val_ds):,}, Test: {len(test_ds):,}\")\n",
    "LOG.log(\"\\n\" + epoch_header_row())\n",
    "\n",
    "best = {\"val_loss\": float('inf'), \"val_r_paper\": float('-inf'), \"epoch\": 0}\n",
    "history = {\"train_loss\": [], \"val_loss\": [], \"val_r_paper\": []}\n",
    "\n",
    "for epoch in range(1, cfg.epochs + 1):\n",
    "    # Loss Schedule\n",
    "    if epoch <= 5:\n",
    "        criterion.w_mse, criterion.w_sisnr = 1.0, 1.0 # (Or 0.0/1.0 if strictly phase 1)\n",
    "    else:\n",
    "        criterion.w_mse, criterion.w_sisnr = 1.0, 1.0\n",
    "\n",
    "    tr_logs = train_one_epoch(epoch)\n",
    "    va_logs = evaluate(val_loader)\n",
    "    \n",
    "    LOG.log(epoch_row(epoch, optimizer.param_groups[0][\"lr\"], tr_logs, va_logs))\n",
    "    \n",
    "    history[\"train_loss\"].append(tr_logs[\"loss\"])\n",
    "    history[\"val_loss\"].append(va_logs[\"val_loss\"])\n",
    "    history[\"val_r_paper\"].append(va_logs[\"val_r_paper\"])\n",
    "    \n",
    "    if va_logs[\"val_loss\"] < best[\"val_loss\"]:\n",
    "        best.update({\"val_loss\": va_logs[\"val_loss\"], \"val_r_paper\": va_logs[\"val_r_paper\"], \"epoch\": epoch})\n",
    "        save_ckpt(cfg.save_dir / \"best.pt\", epoch, model, optimizer, scaler, best)\n",
    "\n",
    "with open(cfg.save_dir / \"history.json\", \"w\") as f: json.dump(history, f, indent=2)\n",
    "LOG.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a245c23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-12T15:59:51.516745Z",
     "iopub.status.busy": "2025-11-12T15:59:51.516459Z",
     "iopub.status.idle": "2025-11-12T16:03:41.428909Z",
     "shell.execute_reply": "2025-11-12T16:03:41.427943Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using latest experiment directory: ctdcrn_runs/exp70\n",
      "Loading from: ctdcrn_runs/exp70/best.pt\n",
      "Detected _orig_mod.* keys in checkpoint → stripping prefix for eval.\n",
      "Model loaded ✔ (strict=False)\n",
      "Tensor keys in model:      351\n",
      "Tensor keys in checkpoint: 351\n",
      "Matched tensor keys:       351 / 351\n",
      "Missing keys:              0\n",
      "Unexpected keys:           0\n",
      "Matched parameter elements: 378308 / 378308 (100.00%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2710697/930862432.py:82: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ck = torch.load(ckpt_path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GOLDMixAWGNDataset] kept 212,992 / 2,555,904 frames (mods=['BPSK', 'QPSK'], SNR_values=None, SNR_range=(-20, 30))\n",
      "\n",
      "                            total          mse      -si-snr      pearson\n",
      "------------------------------------------------------------------------\n",
      "total                 1685.591275  1684.355342     1.235933    -0.003592\n",
      "src1.real             1827.614910  1826.144195     1.470715     0.634825\n",
      "src1.imag             1765.252123  1763.849984     1.402139    -0.638009\n",
      "src1.avg              1796.433517  1794.997090     1.436427    -0.001592\n",
      "src2.real             1583.651230  1582.499133     1.152097     0.651543\n",
      "src2.imag             1565.846837  1564.928057     0.918780    -0.662725\n",
      "src2.avg              1574.749033  1573.713595     1.035438    -0.005591\n",
      "real avg across srcs  1705.633070  1704.321664     1.311406     0.643184\n",
      "imag avg across srcs  1665.549480  1664.389020     1.160460    -0.650367\n",
      "\n",
      "Summary → total=1685.591275  mse=1684.355342  -si-snr=1.235933  pearson=-0.003592\n",
      "\n",
      "Saved detailed table to train.log ✔\n",
      "Saved waveform_gt_vs_pred.png ✔\n",
      "Saved spectrograms_2x2.png ✔\n",
      "Saved loss_curves_eval.png & val_corr_curves_eval.png ✔\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# Phase 6: Post-Training Evaluation (self-contained)\n",
    "# ===============================\n",
    "import os, json, numpy as np\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---- REQUIREMENTS in scope from earlier phases ----\n",
    "# - CTDCRN (model class)\n",
    "# - GOLDMixAWGNDataset, collate_mix  (dataset & collator)\n",
    "# If these aren't in scope (e.g., new kernel), import them from your project:\n",
    "# from dataset import GOLDMixAWGNDataset, collate_mix\n",
    "\n",
    "# ---------------- tiny helpers ----------------\n",
    "@torch.no_grad()\n",
    "def _pearson_1d(a: torch.Tensor, b: torch.Tensor, eps: float = 1e-8) -> torch.Tensor:\n",
    "    # a,b: (B, T) real\n",
    "    a = a - a.mean(dim=-1, keepdim=True)\n",
    "    b = b - b.mean(dim=-1, keepdim=True)\n",
    "    num = (a * b).sum(dim=-1)\n",
    "    den = a.norm(dim=-1) * b.norm(dim=-1) + eps\n",
    "    return num / den  # (B,)\n",
    "\n",
    "@torch.no_grad()\n",
    "def _si_snr_real(pred_r: torch.Tensor, target_r: torch.Tensor, eps: float = 1e-8) -> torch.Tensor:\n",
    "    # pred_r/target_r: (B, C, T) -> (B,)\n",
    "    x = pred_r - pred_r.mean(dim=-1, keepdim=True)\n",
    "    s = target_r - target_r.mean(dim=-1, keepdim=True)\n",
    "    s_pow = (s ** 2).sum(dim=-1, keepdim=True) + eps\n",
    "    proj = ((x * s).sum(dim=-1, keepdim=True) / s_pow) * s\n",
    "    e = x - proj\n",
    "    si = 10 * torch.log10((proj.pow(2).sum(dim=-1) + eps) / (e.pow(2).sum(dim=-1) + eps))\n",
    "    return si.mean(dim=1)  # (B,)\n",
    "\n",
    "@torch.no_grad()\n",
    "def _pearson_lane(pred_lane: torch.Tensor, tgt_lane: torch.Tensor) -> torch.Tensor:\n",
    "    # lane: (B,C,T) -> collapse C,T then Pearson (B,)\n",
    "    return _pearson_1d(pred_lane.flatten(1), tgt_lane.flatten(1))\n",
    "\n",
    "def _tee_log(path: Path, msg: str):\n",
    "    print(msg)\n",
    "    try:\n",
    "        with open(path, \"a\", encoding=\"utf-8\") as f:\n",
    "            f.write(msg + (\"\" if msg.endswith(\"\\n\") else \"\\n\"))\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "# ---------------- reload latest experiment ----------------\n",
    "root = Path(\"./ctdcrn_runs\")\n",
    "exp_folders = sorted([d for d in root.glob(\"exp*\") if d.is_dir()],\n",
    "                     key=lambda x: int(x.name.replace(\"exp\", \"\")))\n",
    "if not exp_folders:\n",
    "    raise FileNotFoundError(\"No experiment folders found in ./ctdcrn_runs/\")\n",
    "exp_dir = exp_folders[-1]  # latest\n",
    "print(f\"Using latest experiment directory: {exp_dir}\")\n",
    "\n",
    "ckpt_path   = exp_dir / \"best.pt\"\n",
    "config_path = exp_dir / \"config.json\"\n",
    "hist_path   = exp_dir / \"history.json\"\n",
    "log_path    = exp_dir / \"train.log\"\n",
    "\n",
    "print(f\"Loading from: {ckpt_path}\")\n",
    "cfg_dict = json.load(open(config_path))\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ---------------- rebuild model ----------------\n",
    "model = CTDCRN(\n",
    "    channels=cfg_dict[\"model\"][\"channels\"],\n",
    "    che_mid=cfg_dict[\"model\"][\"che_mid\"],\n",
    "    ksize=cfg_dict[\"model\"][\"ksize\"],\n",
    "    n_src=cfg_dict[\"n_sources\"],\n",
    "    n_cdcm_a=cfg_dict[\"model\"][\"n_cdcm_a\"],\n",
    "    n_cdcm_b=cfg_dict[\"model\"][\"n_cdcm_b\"],\n",
    "    slope=cfg_dict[\"model\"][\"slope\"]\n",
    ").to(device)\n",
    "\n",
    "# ---- FIX: handle torch.compile checkpoints with _orig_mod.* keys\n",
    "#      and print how many params matched ----\n",
    "ck = torch.load(ckpt_path, map_location=device)\n",
    "\n",
    "# Some runs might save the raw state_dict, others a dict with \"model\" key.\n",
    "state = ck.get(\"model\", ck)\n",
    "\n",
    "# If the model was saved while compiled, keys look like \"_orig_mod.che.conv1.Wr\"\n",
    "if any(k.startswith(\"_orig_mod.\") for k in state.keys()):\n",
    "    print(\"Detected _orig_mod.* keys in checkpoint → stripping prefix for eval.\")\n",
    "    cleaned_state = {}\n",
    "    prefix = \"_orig_mod.\"\n",
    "    plen = len(prefix)\n",
    "    for k, v in state.items():\n",
    "        if k.startswith(prefix):\n",
    "            cleaned_state[k[plen:]] = v\n",
    "        else:\n",
    "            cleaned_state[k] = v\n",
    "    state = cleaned_state\n",
    "\n",
    "def _count_elems(sd):\n",
    "    return sum(v.numel() for v in sd.values())\n",
    "\n",
    "model_state = model.state_dict()\n",
    "missing, unexpected = model.load_state_dict(state, strict=False)\n",
    "print(\"Model loaded ✔ (strict=False)\")\n",
    "\n",
    "# ---- tensor (key) counts ----\n",
    "n_model_keys   = len(model_state)\n",
    "n_state_keys   = len(state)\n",
    "n_missing      = len(missing)\n",
    "n_unexpected   = len(unexpected)\n",
    "n_matched_keys = n_model_keys - n_missing\n",
    "\n",
    "print(f\"Tensor keys in model:      {n_model_keys}\")\n",
    "print(f\"Tensor keys in checkpoint: {n_state_keys}\")\n",
    "print(f\"Matched tensor keys:       {n_matched_keys} / {n_model_keys}\")\n",
    "print(f\"Missing keys:              {n_missing}\")\n",
    "print(f\"Unexpected keys:           {n_unexpected}\")\n",
    "\n",
    "# ---- element (parameter) counts ----\n",
    "matched_elems = 0\n",
    "for k, v in state.items():\n",
    "    if k in model_state and model_state[k].shape == v.shape:\n",
    "        matched_elems += v.numel()\n",
    "\n",
    "total_model_elems = _count_elems(model_state)\n",
    "match_frac = matched_elems / total_model_elems if total_model_elems > 0 else 0.0\n",
    "print(f\"Matched parameter elements: {matched_elems} / {total_model_elems} \"\n",
    "      f\"({match_frac:.2%})\")\n",
    "\n",
    "if missing:\n",
    "    print(\"Example missing keys:\", list(missing)[:5], \"...\")\n",
    "if unexpected:\n",
    "    print(\"Example unexpected keys:\", list(unexpected)[:5], \"...\")\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# ---------------- make test loader (independent) ----------------\n",
    "# You can override the dataset path via env:  DATA_PATH=/path/to/HDF5\n",
    "data_path = os.getenv(\"DATA_PATH\", \"/home/bss/data/GOLD_XYZ_OSC.0001_1024.hdf5\")\n",
    "mods     = cfg_dict.get(\"mods\", [\"BPSK\", \"QPSK\"])\n",
    "test_snr = cfg_dict.get(\"test_snr\", 20)\n",
    "\n",
    "test_ds = GOLDMixAWGNDataset(\n",
    "    h5_path=data_path,\n",
    "    filter_mods=mods,\n",
    "    snr_range=(-20, 30),\n",
    "    sir_db_range=(-3.0, 3.0),\n",
    "    awgn_snr_db_range=(test_snr, test_snr),  # fixed test SNR\n",
    "    normalize_frames=True,\n",
    "    return_meta=False,\n",
    ")\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "def make_loader(ds, batch_size=cfg_dict.get(\"batch_size\", 256)):\n",
    "    try:\n",
    "        ncpu = os.cpu_count() or 8\n",
    "        num_workers = max(2, min(8, ncpu - 2))\n",
    "    except Exception:\n",
    "        num_workers = 4\n",
    "    return DataLoader(\n",
    "        ds,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        prefetch_factor=4,\n",
    "        persistent_workers=True,\n",
    "        pin_memory=True,\n",
    "        multiprocessing_context=\"spawn\",\n",
    "        collate_fn=collate_mix,\n",
    "        drop_last=False,\n",
    "        shuffle=False,\n",
    "    )\n",
    "\n",
    "test_loader = make_loader(test_ds, batch_size=min(256, cfg_dict.get(\"batch_size\", 256)))\n",
    "\n",
    "# ---------------- enhanced test evaluation (per source × lane table) ----------------\n",
    "@torch.no_grad()\n",
    "def evaluate_detailed(model, loader, device):\n",
    "    \"\"\"\n",
    "    Returns dict with:\n",
    "      totals: dict(total, mse, neg_sisnr, pearson)\n",
    "      table:  shape (rows, cols) with rows in requested order and cols [total, mse, -si-snr, pearson]\n",
    "      row_names: matching labels for 'table' rows\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    n_batches = 0\n",
    "\n",
    "    # Accumulators over batches\n",
    "    # per source (2) × lane (2) × metrics (mse, si_snr, pearson)\n",
    "    acc = np.zeros((2, 2, 3), dtype=np.float64)\n",
    "\n",
    "    for xb, yb in loader:\n",
    "        xb = xb.to(device, non_blocking=True)\n",
    "        yb = [t.to(device, non_blocking=True) for t in yb]  # list of 2 tensors (B,2,1,T)\n",
    "        outs = model(xb)  # list of 2 tensors (B,2,1,T)\n",
    "\n",
    "        # For each source and lane compute metrics\n",
    "        for s in range(2):\n",
    "            # lanes\n",
    "            pr, pi = outs[s][:, 0], outs[s][:, 1]   # (B,1,T)\n",
    "            tr, ti = yb[s][:, 0],  yb[s][:, 1]\n",
    "\n",
    "            # MSE (per lane)\n",
    "            mse_r = F.mse_loss(pr, tr).item()\n",
    "            mse_i = F.mse_loss(pi, ti).item()\n",
    "\n",
    "            # SI-SNR (per lane): reuse real SI-SNR on each lane separately\n",
    "            sisnr_r = _si_snr_real(pr, tr).mean().item()\n",
    "            sisnr_i = _si_snr_real(pi, ti).mean().item()\n",
    "\n",
    "            # Pearson (per lane)\n",
    "            rho_r = _pearson_lane(pr, tr).mean().item()\n",
    "            rho_i = _pearson_lane(pi, ti).mean().item()\n",
    "\n",
    "            # accumulate: lane 0 = Real, lane 1 = Imag\n",
    "            acc[s, 0, 0] += mse_r\n",
    "            acc[s, 1, 0] += mse_i\n",
    "            acc[s, 0, 1] += sisnr_r\n",
    "            acc[s, 1, 1] += sisnr_i\n",
    "            acc[s, 0, 2] += rho_r\n",
    "            acc[s, 1, 2] += rho_i\n",
    "\n",
    "        n_batches += 1\n",
    "\n",
    "    acc /= max(1, n_batches)  # average over batches\n",
    "\n",
    "    # Build rows in the requested order:\n",
    "    # header \"total\" row (averaged across sources & lanes):\n",
    "    mse_total    = acc[:, :, 0].mean()\n",
    "    sisnr_total  = acc[:, :, 1].mean()\n",
    "    rho_total    = acc[:, :, 2].mean()\n",
    "    total_loss   = mse_total - sisnr_total  # your training loss convention\n",
    "\n",
    "    # Per-source avg (across lanes)\n",
    "    src1_avg = acc[0].mean(axis=0)  # [mse, sisnr, rho]\n",
    "    src2_avg = acc[1].mean(axis=0)\n",
    "\n",
    "    # Real/Imag avg across sources\n",
    "    real_across = acc[:, 0, :].mean(axis=0)  # metrics for Real averaged across sources\n",
    "    imag_across = acc[:, 1, :].mean(axis=0)\n",
    "\n",
    "    # Table rows (each row has [total, mse, -si-snr, pearson])\n",
    "    rows = []\n",
    "    names = []\n",
    "\n",
    "    # Total row\n",
    "    rows.append([total_loss, mse_total, -sisnr_total, rho_total])\n",
    "    names.append(\"total\")\n",
    "\n",
    "    # Src-1 Real\n",
    "    rows.append([acc[0,0,0] - acc[0,0,1], acc[0,0,0], -acc[0,0,1], acc[0,0,2]])\n",
    "    names.append(\"src1.real\")\n",
    "    # Src-1 Imag\n",
    "    rows.append([acc[0,1,0] - acc[0,1,1], acc[0,1,0], -acc[0,1,1], acc[0,1,2]])\n",
    "    names.append(\"src1.imag\")\n",
    "    # Src-1 Avg\n",
    "    rows.append([src1_avg[0] - src1_avg[1], src1_avg[0], -src1_avg[1], src1_avg[2]])\n",
    "    names.append(\"src1.avg\")\n",
    "\n",
    "    # Src-2 Real\n",
    "    rows.append([acc[1,0,0] - acc[1,0,1], acc[1,0,0], -acc[1,0,1], acc[1,0,2]])\n",
    "    names.append(\"src2.real\")\n",
    "    # Src-2 Imag\n",
    "    rows.append([acc[1,1,0] - acc[1,1,1], acc[1,1,0], -acc[1,1,1], acc[1,1,2]])\n",
    "    names.append(\"src2.imag\")\n",
    "    # Src-2 Avg\n",
    "    rows.append([src2_avg[0] - src2_avg[1], src2_avg[0], -src2_avg[1], src2_avg[2]])\n",
    "    names.append(\"src2.avg\")\n",
    "\n",
    "    # Real avg across srcs\n",
    "    rows.append([real_across[0] - real_across[1], real_across[0], -real_across[1], real_across[2]])\n",
    "    names.append(\"real avg across srcs\")\n",
    "    # Imag avg across srcs\n",
    "    rows.append([imag_across[0] - imag_across[1], imag_across[0], -imag_across[1], imag_across[2]])\n",
    "    names.append(\"imag avg across srcs\")\n",
    "\n",
    "    table = np.array(rows, dtype=np.float64)\n",
    "\n",
    "    # also return simple totals for quick reference\n",
    "    totals = {\n",
    "        \"total\": total_loss,\n",
    "        \"mse\": mse_total,\n",
    "        \"neg_sisnr\": -sisnr_total,\n",
    "        \"pearson\": rho_total,\n",
    "    }\n",
    "    return {\"totals\": totals, \"table\": table, \"row_names\": names}\n",
    "\n",
    "# ---------- run test, print + append to train.log ----------\n",
    "stats = evaluate_detailed(model, test_loader, device)\n",
    "\n",
    "# Pretty table print\n",
    "header = f\"{'':<20} {'total':>12} {'mse':>12} {'-si-snr':>12} {'pearson':>12}\"\n",
    "sep    = \"-\" * len(header)\n",
    "lines = [header, sep]\n",
    "for name, row in zip(stats[\"row_names\"], stats[\"table\"]):\n",
    "    lines.append(f\"{name:<20} {row[0]:12.6f} {row[1]:12.6f} {row[2]:12.6f} {row[3]:12.6f}\")\n",
    "pretty = \"\\n\".join(lines)\n",
    "\n",
    "_tee_log(log_path, \"\\n\" + pretty + \"\\n\")\n",
    "\n",
    "# Also show a short one-line summary\n",
    "_tee_log(log_path, f\"Summary → total={stats['totals']['total']:.6f}  \"\n",
    "                   f\"mse={stats['totals']['mse']:.6f}  \"\n",
    "                   f\"-si-snr={stats['totals']['neg_sisnr']:.6f}  \"\n",
    "                   f\"pearson={stats['totals']['pearson']:.6f}\")\n",
    "\n",
    "print(\"\\nSaved detailed table to train.log ✔\")\n",
    "\n",
    "# ---------------- sample predictions (first batch) ----------------\n",
    "xb, yb = next(iter(test_loader))\n",
    "xb = xb.to(device, non_blocking=True)\n",
    "yb = [t.to(device, non_blocking=True) for t in yb]\n",
    "outs = model(xb)\n",
    "\n",
    "# Waveform GT vs Pred for sample idx=0\n",
    "idx = 0\n",
    "fig, axes = plt.subplots(2, 2, figsize=(10, 6))\n",
    "titles = [\"Source-1 Real vs Pred\", \"Source-1 Imag vs Pred\",\n",
    "          \"Source-2 Real vs Pred\", \"Source-2 Imag vs Pred\"]\n",
    "for s in range(2):\n",
    "    for c in range(2):  # 0=real, 1=imag\n",
    "        ax = axes[s, c]\n",
    "        gt   = yb[s][idx, c, 0, :].detach().cpu().numpy()\n",
    "        pred = outs[s][idx, c, 0, :].detach().cpu().numpy()\n",
    "        ax.plot(gt,   label=\"GT\",   alpha=0.7)\n",
    "        ax.plot(pred, label=\"Pred\", alpha=0.7)\n",
    "        ax.set_title(titles[s*2 + c])\n",
    "        ax.legend(fontsize=8)\n",
    "plt.tight_layout()\n",
    "plt.savefig(exp_dir / \"waveform_gt_vs_pred.png\", dpi=150)\n",
    "plt.close()\n",
    "print(\"Saved waveform_gt_vs_pred.png ✔\")\n",
    "\n",
    "# ---------------- spectrograms: 2x2 grid in a single file ----------------\n",
    "def _spec(ax, sig_1d, title):\n",
    "    sig_np = sig_1d.detach().cpu().float().view(-1).numpy()\n",
    "    ax.specgram(sig_np, NFFT=128, Fs=1, noverlap=64, cmap=\"magma\")\n",
    "    ax.set_title(title, fontsize=10)\n",
    "    ax.set_xlabel(\"Time\")\n",
    "    ax.set_ylabel(\"Freq\")\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(10, 6))\n",
    "_spec(axes[0,0], yb[0][idx, 0, 0, :], \"GT Src-1 Real\")\n",
    "_spec(axes[0,1], outs[0][idx, 0, 0, :], \"Pred Src-1 Real\")\n",
    "_spec(axes[1,0], yb[1][idx, 0, 0, :], \"GT Src-2 Real\")\n",
    "_spec(axes[1,1], outs[1][idx, 0, 0, :], \"Pred Src-2 Real\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(exp_dir / \"spectrograms_2x2.png\", dpi=150)\n",
    "plt.close()\n",
    "print(\"Saved spectrograms_2x2.png ✔\")\n",
    "\n",
    "# ---------------- training history curves (if present) ----------------\n",
    "try:\n",
    "    with open(hist_path, \"r\") as f:\n",
    "        hist = json.load(f)\n",
    "\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.plot(hist[\"train_loss\"], label=\"Train Loss\")\n",
    "    plt.plot(hist[\"val_loss\"], label=\"Val Loss\")\n",
    "    plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\"); plt.legend()\n",
    "    plt.title(\"Train/Val Loss\")\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(exp_dir / \"loss_curves_eval.png\", dpi=150)\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.plot(hist[\"val_r_paper\"], label=\"Val Pearson ρ\")\n",
    "    plt.xlabel(\"Epoch\"); plt.ylabel(\"ρ\")\n",
    "    plt.title(\"Validation Correlation (PIT)\")\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(exp_dir / \"val_corr_curves_eval.png\", dpi=150)\n",
    "    plt.close()\n",
    "\n",
    "    print(\"Saved loss_curves_eval.png & val_corr_curves_eval.png ✔\")\n",
    "except Exception as e:\n",
    "    print(f\"No history.json found ({e})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d618836",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-12T16:03:41.432204Z",
     "iopub.status.busy": "2025-11-12T16:03:41.432055Z",
     "iopub.status.idle": "2025-11-12T16:03:41.437132Z",
     "shell.execute_reply": "2025-11-12T16:03:41.436140Z"
    }
   },
   "outputs": [],
   "source": [
    "# # =============================================\n",
    "# # Phase 6: Post-Training Evaluation & Plotting\n",
    "# # =============================================\n",
    "# import os, json, torch, numpy as np, matplotlib.pyplot as plt\n",
    "# from pathlib import Path\n",
    "# from torch.utils.data import Subset, DataLoader\n",
    "\n",
    "# # ---------- locate latest experiment ----------\n",
    "# root = Path(\"/home/bss/ctdcrn_runs\")\n",
    "# exp_dirs = sorted([d for d in root.iterdir() if d.is_dir() and d.name.startswith(\"exp\")],\n",
    "#                   key=lambda p: p.stat().st_mtime)\n",
    "# assert exp_dirs, f\"No experiments found in {root}\"\n",
    "# exp = exp_dirs[-1]\n",
    "# print(f\"[✓] Using latest experiment: {exp.name}\")\n",
    "\n",
    "# cfg_path = exp / \"config.json\"\n",
    "# ckpt_path = exp / \"best.pt\"\n",
    "# hist_path = exp / \"history.json\"\n",
    "\n",
    "# cfg = json.load(open(cfg_path))\n",
    "# print(json.dumps(cfg, indent=2))\n",
    "\n",
    "# # ---------- rebuild model ----------\n",
    "\n",
    "\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model = CTDCRN(\n",
    "#     channels=cfg[\"model\"][\"channels\"],\n",
    "#     che_mid=cfg[\"model\"][\"che_mid\"],\n",
    "#     ksize=cfg[\"model\"][\"ksize\"],\n",
    "#     n_src=cfg[\"n_sources\"],\n",
    "#     n_cdcm_a=cfg[\"model\"][\"n_cdcm_a\"],\n",
    "#     n_cdcm_b=cfg[\"model\"][\"n_cdcm_b\"],\n",
    "#     slope=cfg[\"model\"][\"slope\"]\n",
    "# ).to(device)\n",
    "\n",
    "# ck = torch.load(ckpt_path, map_location=device, weights_only=False)\n",
    "# model.load_state_dict(ck[\"model\"], strict=False)\n",
    "# model.eval()\n",
    "# print(f\"[✓] Loaded checkpoint @ epoch {ck.get('epoch')}\")\n",
    "\n",
    "# # ---------- plot training curves ----------\n",
    "# if hist_path.exists():\n",
    "#     hist = json.load(open(hist_path))\n",
    "#     plt.figure(figsize=(6,4))\n",
    "#     plt.plot(hist[\"train_loss\"], label=\"Train Loss\")\n",
    "#     plt.plot(hist[\"val_loss\"], label=\"Val Loss\")\n",
    "#     plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\"); plt.legend(); plt.grid(True)\n",
    "#     plt.title(\"Training vs Validation Loss\"); plt.tight_layout()\n",
    "#     plt.savefig(exp / \"loss_curve.png\", dpi=150)\n",
    "#     plt.close()\n",
    "\n",
    "#     plt.figure(figsize=(6,4))\n",
    "#     plt.plot(hist[\"val_r_paper\"], label=\"Val Pearson ρ\")\n",
    "#     plt.xlabel(\"Epoch\"); plt.ylabel(\"ρ\"); plt.legend(); plt.grid(True)\n",
    "#     plt.title(\"Validation Pearson Correlation\"); plt.tight_layout()\n",
    "#     plt.savefig(exp / \"pearson_curve.png\", dpi=150)\n",
    "#     plt.close()\n",
    "#     print(\"[✓] Saved loss and Pearson-ρ curves\")\n",
    "\n",
    "# # ---------- build test loader ----------\n",
    "# data_path = \"/home/bss/data/GOLD_XYZ_OSC.0001_1024.hdf5\"\n",
    "# test_ds = GOLDMixAWGNDataset(\n",
    "#     h5_path=data_path,\n",
    "#     filter_mods=cfg[\"mods\"],\n",
    "#     snr_range=(-20,30),\n",
    "#     sir_db_range=(-3,3),\n",
    "#     awgn_snr_db_range=(cfg[\"test_snr\"], cfg[\"test_snr\"]),\n",
    "#     normalize_frames=True,\n",
    "#     return_meta=False,\n",
    "# )\n",
    "# N = len(test_ds)\n",
    "# test_loader = DataLoader(test_ds, batch_size=16, shuffle=False,\n",
    "#                          num_workers=4, collate_fn=collate_mix)\n",
    "\n",
    "# # ---------- metric helpers ----------\n",
    "# @torch.no_grad()\n",
    "# def pearson_r_paper_PIT_torch(outs, tgts, eps=1e-8):\n",
    "#     # identical to your phase-5 version\n",
    "#     def _pearson_1d(a,b):\n",
    "#         a=a-a.mean(-1,True); b=b-b.mean(-1,True)\n",
    "#         return (a*b).sum(-1)/(a.norm(dim=-1)*b.norm(dim=-1)+eps)\n",
    "#     def _collapse(x): return x.mean(1)\n",
    "#     def lanes(x):\n",
    "#         return (_collapse(x[:,0]) if x.ndim==4 else x[:,0,:],\n",
    "#                 _collapse(x[:,1]) if x.ndim==4 else x[:,1,:])\n",
    "#     y0r,y0i=lanes(outs[0]); y1r,y1i=lanes(outs[1])\n",
    "#     s0r,s0i=lanes(tgts[0]); s1r,s1i=lanes(tgts[1])\n",
    "#     r00=0.5*(_pearson_1d(y0r,s0r)+_pearson_1d(y0i,s0i))\n",
    "#     r11=0.5*(_pearson_1d(y1r,s1r)+_pearson_1d(y1i,s1i))\n",
    "#     r01=0.5*(_pearson_1d(y0r,s1r)+_pearson_1d(y0i,s1i))\n",
    "#     r10=0.5*(_pearson_1d(y1r,s0r)+_pearson_1d(y1i,s0i))\n",
    "#     best=torch.maximum(r00+r11,r01+r10)*0.5\n",
    "#     return best.mean().item()\n",
    "\n",
    "# # ---------- evaluate on test ----------\n",
    "# mse_fn = complex_mse\n",
    "# sisnr_fn = si_snr_complex\n",
    "# crit = CTDCRNLoss(w_mse=1.0, w_sisnr=0.5)\n",
    "\n",
    "# def eval_test():\n",
    "#     model.eval()\n",
    "#     tot, mse_sum, sisnr_sum, rho_sum = 0,0,0,0\n",
    "#     per_src = [dict(mse=0,sisnr=0,rho=0) for _ in range(2)]\n",
    "#     n=0\n",
    "#     with torch.no_grad():\n",
    "#         for xb, yb in test_loader:\n",
    "#             xb=[t.to(device) if torch.is_tensor(t) else t for t in xb]\n",
    "#             xb, yb = xb.to(device), [t.to(device) for t in yb]\n",
    "#             outs = model(xb)\n",
    "#             loss,_ = crit(outs, yb)\n",
    "#             tot += loss.item()\n",
    "#             # combined metrics\n",
    "#             mse_sum += mse_fn(torch.cat(outs,1), torch.cat(yb,1)).item()\n",
    "#             sisnr_sum += -sisnr_fn(torch.cat(outs,1), torch.cat(yb,1)).item()\n",
    "#             rho_sum += pearson_r_paper_PIT_torch(outs, yb)\n",
    "#             # per-source\n",
    "#             for i in range(2):\n",
    "#                 per_src[i][\"mse\"] += mse_fn(outs[i], yb[i]).item()\n",
    "#                 per_src[i][\"sisnr\"] += -sisnr_fn(outs[i], yb[i]).item()\n",
    "#                 xr,xi = outs[i][:,0].mean(1), outs[i][:,1].mean(1)\n",
    "#                 yr,yi = yb[i][:,0].mean(1), yb[i][:,1].mean(1)\n",
    "#                 per_src[i][\"rho\"] += float(_pearson_1d(xr,yr).mean())\n",
    "#             n+=1\n",
    "#     res = {\n",
    "#         \"test_loss\": tot/n,\n",
    "#         \"mse\": mse_sum/n,\n",
    "#         \"-si_snr\": sisnr_sum/n,\n",
    "#         \"pearson_r\": rho_sum/n,\n",
    "#         \"per_src\": [{k:v/n for k,v in d.items()} for d in per_src],\n",
    "#     }\n",
    "#     return res\n",
    "\n",
    "# results = eval_test()\n",
    "# print(json.dumps(results, indent=2))\n",
    "# json.dump(results, open(exp/\"test_metrics.json\",\"w\"), indent=2)\n",
    "\n",
    "# # ---------- visualize one batch ----------\n",
    "# xb, yb = next(iter(test_loader))\n",
    "# xb, yb = xb.to(device), [t.to(device) for t in yb]\n",
    "# outs = model(xb)\n",
    "\n",
    "# idx = 0  # pick first example\n",
    "# for s in range(2):\n",
    "#     gt = yb[s][idx].cpu().numpy()   # (2,1,T)\n",
    "#     pr = outs[s][idx].detach().cpu().numpy()\n",
    "#     T = gt.shape[-1]; t = np.arange(T)\n",
    "\n",
    "#     fig,axs = plt.subplots(2,2,figsize=(10,5))\n",
    "#     axs[0,0].plot(t, gt[0,0], label=\"GT-Real\"); axs[0,0].plot(t, pr[0,0], label=\"Pred-Real\", alpha=0.7)\n",
    "#     axs[0,1].plot(t, gt[1,0], label=\"GT-Imag\"); axs[0,1].plot(t, pr[1,0], label=\"Pred-Imag\", alpha=0.7)\n",
    "#     axs[0,0].legend(); axs[0,1].legend(); axs[0,0].set_title(f\"Source {s} Waveforms\")\n",
    "\n",
    "#     # spectrograms\n",
    "#     from matplotlib.colors import LogNorm\n",
    "#     fgt, tgt, Sgt = plt.specgram(gt[0,0], NFFT=128, Fs=1.0, noverlap=64, scale='dB')\n",
    "#     axs[1,0].imshow(Sgt, origin=\"lower\", aspect=\"auto\", cmap=\"magma\",\n",
    "#                     extent=[tgt.min(), tgt.max(), fgt.min(), fgt.max()])\n",
    "#     fpr, tpr, Spr = plt.specgram(pr[0,0], NFFT=128, Fs=1.0, noverlap=64, scale='dB')\n",
    "#     axs[1,1].imshow(Spr, origin=\"lower\", aspect=\"auto\", cmap=\"magma\",\n",
    "#                     extent=[tpr.min(), tpr.max(), fpr.min(), fpr.max()])\n",
    "#     axs[1,0].set_title(\"GT Spectrogram\"); axs[1,1].set_title(\"Pred Spectrogram\")\n",
    "\n",
    "#     plt.tight_layout()\n",
    "#     plt.savefig(exp / f\"source{s}_wave_spectrogram.png\", dpi=150)\n",
    "#     plt.close()\n",
    "# print(\"[✓] Saved waveform + spectrogram plots\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f58107c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-12T16:03:41.439727Z",
     "iopub.status.busy": "2025-11-12T16:03:41.439597Z",
     "iopub.status.idle": "2025-11-12T16:03:41.442360Z",
     "shell.execute_reply": "2025-11-12T16:03:41.441623Z"
    }
   },
   "outputs": [],
   "source": [
    "# # ---------------- run ----------------\n",
    "# best = {\"val_loss\": float(\"inf\"), \"epoch\": 0}\n",
    "# best_path = cfg.save_dir / \"best.pt\"\n",
    "\n",
    "# for epoch in range(1, cfg.epochs + 1):\n",
    "#     tr = train_one_epoch(epoch)\n",
    "#     va = evaluate(val_loader)\n",
    "\n",
    "#     # headings printed each epoch (more readable)\n",
    "#     LOG.log(\"\\n\" + epoch_header_row())\n",
    "#     LOG.log(epoch_row(epoch, optimizer.param_groups[0]['lr'], tr, va))\n",
    "\n",
    "#     # track history\n",
    "#     history[\"train_loss\"].append(tr[\"loss\"])\n",
    "#     history[\"val_loss\"].append(va[\"val_loss\"])\n",
    "#     history[\"val_r_paper\"].append(va[\"val_r_paper\"])\n",
    "\n",
    "#     # slope reminder if saturated (based on r_paper)\n",
    "#     if epoch >= 4 and epoch % 2 == 0:\n",
    "#         recent = history[\"val_r_paper\"][-4:]\n",
    "#         if len(recent) == 4 and max(recent) - min(recent) < 1e-3:\n",
    "#             LOG.log(\"  ⚠️  Validation seems saturated — consider LeakyReLU negative_slope 0.05–0.1.\")\n",
    "\n",
    "#     # checkpoints\n",
    "#     if va[\"val_loss\"] < best[\"val_loss\"]:\n",
    "#         best.update({\"val_loss\": va[\"val_loss\"], \"epoch\": epoch})\n",
    "#         save_ckpt(best_path, epoch, model, optimizer, scheduler, scaler, best)\n",
    "#     save_ckpt(cfg.save_dir / \"last.pt\", epoch, model, optimizer, scheduler, scaler, best)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d978dde",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-12T16:03:41.445047Z",
     "iopub.status.busy": "2025-11-12T16:03:41.444921Z",
     "iopub.status.idle": "2025-11-12T16:03:41.447738Z",
     "shell.execute_reply": "2025-11-12T16:03:41.447100Z"
    }
   },
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from collections import OrderedDict\n",
    "\n",
    "# def smart_load_ckpt(best_path, model, map_location=\"cuda\", verbose=True):\n",
    "#     \"\"\"\n",
    "#     Loads a checkpoint that may have been saved from:\n",
    "#       - torch.compile()'d model (keys start with '_orig_mod.')\n",
    "#       - DataParallel/DistributedDataParallel ('module.' prefix)\n",
    "\n",
    "#     It:\n",
    "#       1) loads ckpt\n",
    "#       2) normalizes keys (strip '_orig_mod.' and/or 'module.')\n",
    "#       3) loads with strict=False\n",
    "#       4) prints a summary of missing/unexpected keys\n",
    "#     Returns: epoch (if present), and IncompatibleKeys.\n",
    "#     \"\"\"\n",
    "#     ck = torch.load(best_path, map_location=map_location)\n",
    "#     sd = ck.get(\"model\", ck)  # support plain state_dict or dict with \"model\"\n",
    "\n",
    "#     def strip_prefix(k):\n",
    "#         if k.startswith(\"_orig_mod.\"):\n",
    "#             k = k[len(\"_orig_mod.\"):]\n",
    "#         if k.startswith(\"module.\"):\n",
    "#             k = k[len(\"module.\"):]\n",
    "#         return k\n",
    "\n",
    "#     new_sd = OrderedDict((strip_prefix(k), v) for k, v in sd.items())\n",
    "\n",
    "#     # Choose correct target module (compiled or not)\n",
    "#     target = model._orig_mod if hasattr(model, \"_orig_mod\") else model\n",
    "\n",
    "#     # Load with strict=False (architecture may differ slightly)\n",
    "#     incompatible = target.load_state_dict(new_sd, strict=False)\n",
    "\n",
    "#     if verbose:\n",
    "#         miss = list(incompatible.missing_keys)\n",
    "#         unexp = list(incompatible.unexpected_keys)\n",
    "#         print(f\"[smart_load_ckpt] Loaded: {best_path}\")\n",
    "#         print(f\"  Missing keys   : {len(miss)}\")\n",
    "#         if miss:\n",
    "#             print(\"   (showing a few)\", miss[:10])\n",
    "#         print(f\"  Unexpected keys: {len(unexp)}\")\n",
    "#         if unexp:\n",
    "#             print(\"   (showing a few)\", unexp[:10])\n",
    "\n",
    "#         # Quick sanity: how many matched?\n",
    "#         matched = len(new_sd) - len(unexp)\n",
    "#         print(f\"  Matched params : {matched} / {len(new_sd)}\")\n",
    "\n",
    "#     return int(ck.get(\"epoch\", -1)), incompatible\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2313b0a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-12T16:03:41.450395Z",
     "iopub.status.busy": "2025-11-12T16:03:41.450216Z",
     "iopub.status.idle": "2025-11-12T16:03:41.452912Z",
     "shell.execute_reply": "2025-11-12T16:03:41.452115Z"
    }
   },
   "outputs": [],
   "source": [
    "# @torch.no_grad()\n",
    "# def evaluate_test(loader) -> Dict[str, float]:\n",
    "#     model.eval()\n",
    "#     t0 = time.time()\n",
    "#     loss_sum, r_paper_sum, n_batches = 0.0, 0.0, 0\n",
    "#     for batch in loader:\n",
    "#         xb, yb = batch if len(batch) == 2 else (batch[0], batch[1])\n",
    "#         xb, yb = move_batch(xb, yb)\n",
    "#         with amp.autocast(device_type=amp_dev, enabled=use_amp):\n",
    "#             outs = model(xb)\n",
    "#             loss, _ = criterion(outs, yb)\n",
    "#         r_paper = pearson_r_paper_PIT_torch(outs, yb)\n",
    "#         loss_sum    += float(loss)\n",
    "#         r_paper_sum += float(r_paper)\n",
    "#         n_batches   += 1\n",
    "#     n = max(1, n_batches)\n",
    "#     return {\n",
    "#         \"test_loss\": loss_sum / n,\n",
    "#         \"test_r_paper\": r_paper_sum / n,\n",
    "#         \"time_s\": time.time() - t0\n",
    "#     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14090fa7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-12T16:03:41.455314Z",
     "iopub.status.busy": "2025-11-12T16:03:41.455187Z",
     "iopub.status.idle": "2025-11-12T16:03:41.457940Z",
     "shell.execute_reply": "2025-11-12T16:03:41.457041Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Load best and evaluate\n",
    "# best_epoch, incompatible = smart_load_ckpt(best_path, model, map_location=device)\n",
    "\n",
    "# # (Optional) If you compiled the model now, ensure eval on model (compiled handles _orig_mod internally)\n",
    "# test_stats = evaluate_test(test_loader)\n",
    "# print(\n",
    "#     f\"\\nBEST @ epoch {best_epoch} | TEST | \"\n",
    "#     f\"loss={test_stats['test_loss']:.4f}  r_paper={test_stats['test_r_paper']:.4f}  \"\n",
    "#     f\"time={test_stats['time_s']:.1f}s\"\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf09d7d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-12T16:03:41.460377Z",
     "iopub.status.busy": "2025-11-12T16:03:41.460243Z",
     "iopub.status.idle": "2025-11-12T16:03:41.463254Z",
     "shell.execute_reply": "2025-11-12T16:03:41.462504Z"
    }
   },
   "outputs": [],
   "source": [
    "# best_path= \"ctdcrn_runs/exp30/best.pt\"\n",
    "# # ---------------- plots & history save ----------------\n",
    "# # Save history JSON\n",
    "# with open(cfg.save_dir / \"history.json\", \"w\") as f:\n",
    "#     json.dump(history, f, indent=2)\n",
    "\n",
    "# # Plot curves\n",
    "# fig1 = plt.figure(figsize=(7,4))\n",
    "# plt.plot(history[\"train_loss\"], label=\"Train Loss\")\n",
    "# plt.plot(history[\"val_loss\"], label=\"Val Loss\")\n",
    "# plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\"); plt.title(\"Loss Curves\")\n",
    "# plt.legend(); plt.grid(True, alpha=0.3)\n",
    "# plt.tight_layout(); plt.savefig(cfg.save_dir / \"loss_curves.png\", dpi=150); plt.close(fig1)\n",
    "\n",
    "# fig2 = plt.figure(figsize=(7,4))\n",
    "# plt.plot(history[\"val_r_paper\"], label=\"Val r_paper (-1..1)\")\n",
    "# plt.xlabel(\"Epoch\"); plt.ylabel(\"Correlation\")\n",
    "# plt.title(\"Validation Pearson (PIT)\")\n",
    "# plt.legend(); plt.grid(True, alpha=0.3)\n",
    "# plt.tight_layout(); plt.savefig(cfg.save_dir / \"val_corr_curves.png\", dpi=150); plt.close(fig2)\n",
    "\n",
    "# LOG.log(f\"\\nSaved plots and history to: {cfg.save_dir}\")\n",
    "\n",
    "# # ---------------- final test using BEST checkpoint ----------------\n",
    "# @torch.no_grad()\n",
    "# def evaluate_test(loader) -> Dict[str, float]:\n",
    "#     model.eval()\n",
    "#     t0 = time.time()\n",
    "#     loss_sum, r_paper_sum, n_batches = 0.0, 0.0, 0\n",
    "#     for batch in loader:\n",
    "#         xb, yb = batch if len(batch) == 2 else (batch[0], batch[1])\n",
    "#         xb, yb = move_batch(xb, yb)\n",
    "#         with amp.autocast(device_type=amp_dev, enabled=use_amp):\n",
    "#             outs = model(xb)\n",
    "#             loss, _ = criterion(outs, yb)\n",
    "#         r_paper = pearson_r_paper_PIT_torch(outs, yb)\n",
    "#         loss_sum    += float(loss)\n",
    "#         r_paper_sum += float(r_paper)\n",
    "#         n_batches   += 1\n",
    "#     n = max(1, n_batches)\n",
    "#     return {\n",
    "#         \"test_loss\": loss_sum / n,\n",
    "#         \"test_r_paper\": r_paper_sum / n,\n",
    "#         \"time_s\": time.time() - t0\n",
    "#     }\n",
    "\n",
    "# # Load best checkpoint and run on test set\n",
    "# best_epoch = load_ckpt(best_path, model, map_location=device)\n",
    "# test_stats = evaluate_test(test_loader)\n",
    "# LOG.log(\"\\n\" + \"-\"*126)\n",
    "# LOG.log(f\"BEST @ epoch {best_epoch}  |  \"\n",
    "#         f\"TEST @ {TEST_SNR} dB  |  loss={test_stats['test_loss']:.4f}  \"\n",
    "#         f\"r_paper={test_stats['test_r_paper']:.4f}  time={test_stats['time_s']:.1f}s\")\n",
    "# LOG.log(\"-\"*126)\n",
    "\n",
    "# # close log file\n",
    "# LOG.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9b656f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-12T16:03:41.465757Z",
     "iopub.status.busy": "2025-11-12T16:03:41.465626Z",
     "iopub.status.idle": "2025-11-12T16:03:41.470657Z",
     "shell.execute_reply": "2025-11-12T16:03:41.469869Z"
    }
   },
   "outputs": [],
   "source": [
    "# # ===============================\n",
    "# # Phase 5: Result Visualization\n",
    "# # ===============================\n",
    "# import os, json\n",
    "# from pathlib import Path\n",
    "# import torch\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# from IPython.display import display\n",
    "\n",
    "# # ----------------------------\n",
    "# # 1) Epoch-wise result plots\n",
    "# # ----------------------------\n",
    "# def plot_training_curves(save_dir: Path, history_in_mem: dict | None = None, show: bool = True):\n",
    "#     hist_path = save_dir / \"history.json\"\n",
    "#     if history_in_mem is None:\n",
    "#         with open(hist_path, \"r\") as f:\n",
    "#             history = json.load(f)\n",
    "#     else:\n",
    "#         history = history_in_mem\n",
    "\n",
    "#     train_loss = history.get(\"train_loss\", [])\n",
    "#     val_loss   = history.get(\"val_loss\", [])\n",
    "#     val_r      = history.get(\"val_r_paper\", [])\n",
    "\n",
    "#     # Loss curves\n",
    "#     fig1 = plt.figure(figsize=(7,4))\n",
    "#     if train_loss: plt.plot(train_loss, label=\"Train Loss\")\n",
    "#     if val_loss:   plt.plot(val_loss,   label=\"Val Loss\")\n",
    "#     plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\"); plt.title(\"Loss Curves\")\n",
    "#     plt.legend(); plt.grid(True, alpha=0.3); plt.tight_layout()\n",
    "#     out1 = save_dir / \"loss_curves.final.png\"\n",
    "#     plt.savefig(out1, dpi=150)\n",
    "#     if show: display(fig1)\n",
    "#     plt.close(fig1)\n",
    "\n",
    "#     # Val Pearson ρ curve\n",
    "#     fig2 = plt.figure(figsize=(7,4))\n",
    "#     if val_r: plt.plot(val_r, label=\"Val Pearson ρ (PIT)\")\n",
    "#     plt.xlabel(\"Epoch\"); plt.ylabel(\"ρ (−1..1)\"); plt.title(\"Validation Pearson ρ (PIT)\")\n",
    "#     plt.legend(); plt.grid(True, alpha=0.3); plt.tight_layout()\n",
    "#     out2 = save_dir / \"val_corr_curves.final.png\"\n",
    "#     plt.savefig(out2, dpi=150)\n",
    "#     if show: display(fig2)\n",
    "#     plt.close(fig2)\n",
    "\n",
    "#     print(f\"[saved] {out1}\\n[saved] {out2}\")\n",
    "\n",
    "# # ---------------------------------------------\n",
    "# # 2) Predicted vs. Ground Truth (I/Q waveforms)\n",
    "# # ---------------------------------------------\n",
    "# @torch.no_grad()\n",
    "# def _pearson_1d(a: torch.Tensor, b: torch.Tensor, eps: float = 1e-8) -> torch.Tensor:\n",
    "#     a = a - a.mean(dim=-1, keepdim=True)\n",
    "#     b = b - b.mean(dim=-1, keepdim=True)\n",
    "#     num = (a * b).sum(dim=-1)\n",
    "#     den = a.norm(dim=-1) * b.norm(dim=-1) + eps\n",
    "#     return num / den  # (B,)\n",
    "\n",
    "# @torch.no_grad()\n",
    "# def _collapse_channels(x: torch.Tensor) -> torch.Tensor:\n",
    "#     # (B, C, T) -> (B, T)\n",
    "#     return x.mean(dim=1)\n",
    "\n",
    "# @torch.no_grad()\n",
    "# def _lanes_to_BT(x: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "#     \"\"\"\n",
    "#     x: (B,2,1,T) or (B,2,C,T) or (B,2,T) -> returns (xr, xi) each (B,T)\n",
    "#     \"\"\"\n",
    "#     if x.dim() == 4:   # (B,2,C,T)\n",
    "#         xr = _collapse_channels(x[:,0])  # (B,T)\n",
    "#         xi = _collapse_channels(x[:,1])\n",
    "#     elif x.dim() == 3: # (B,2,T)\n",
    "#         xr, xi = x[:,0], x[:,1]\n",
    "#     else:\n",
    "#         raise ValueError(f\"unexpected shape {tuple(x.shape)}\")\n",
    "#     return xr, xi\n",
    "\n",
    "# @torch.no_grad()\n",
    "# def _per_sample_best_perm(outs, tgts) -> torch.Tensor:\n",
    "#     \"\"\"\n",
    "#     outs/tgts: lists of length 2, tensors (B,2,1,T) or (B,2,C,T)\n",
    "#     returns: (B,) boolean tensor:\n",
    "#         True  -> pairing (0->0, 1->1)\n",
    "#         False -> pairing (0->1, 1->0)\n",
    "#     \"\"\"\n",
    "#     y0r, y0i = _lanes_to_BT(outs[0]); y1r, y1i = _lanes_to_BT(outs[1])\n",
    "#     s0r, s0i = _lanes_to_BT(tgts[0]); s1r, s1i = _lanes_to_BT(tgts[1])\n",
    "\n",
    "#     r00 = 0.5*(_pearson_1d(y0r, s0r) + _pearson_1d(y0i, s0i))  # (B,)\n",
    "#     r11 = 0.5*(_pearson_1d(y1r, s1r) + _pearson_1d(y1i, s1i))\n",
    "#     r01 = 0.5*(_pearson_1d(y0r, s1r) + _pearson_1d(y0i, s1i))\n",
    "#     r10 = 0.5*(_pearson_1d(y1r, s0r) + _pearson_1d(y1i, s0i))\n",
    "\n",
    "#     sum_diag  = r00 + r11\n",
    "#     sum_off   = r01 + r10\n",
    "#     choose_diag = sum_diag >= sum_off   # (B,)\n",
    "#     return choose_diag\n",
    "\n",
    "# @torch.no_grad()\n",
    "# def plot_pred_vs_gt(\n",
    "#     model,\n",
    "#     loader,\n",
    "#     device,\n",
    "#     save_dir: \"Path\",\n",
    "#     pick=\"best\",    # \"best\" (highest mean ρ) or int index\n",
    "#     max_time=1024,  # plot first T samples if you want to zoom in\n",
    "#     show: bool = True\n",
    "# ):\n",
    "#     model.eval()\n",
    "#     batch = next(iter(loader))\n",
    "#     xb, yb = batch if len(batch) == 2 else (batch[0], batch[1])\n",
    "#     xb = xb.to(device)\n",
    "#     yb = [t.to(device) for t in yb]\n",
    "\n",
    "#     # Forward\n",
    "#     outs = model(xb)  # list of length 2, each (B,2,1,T) or (B,2,C,T)\n",
    "\n",
    "#     # Figure out the best pairing per sample\n",
    "#     choose_diag = _per_sample_best_perm(outs, yb)  # (B,)\n",
    "\n",
    "#     # Compute per-sample mean ρ for selection\n",
    "#     def _mean_r_for_pairing(diag: torch.Tensor) -> torch.Tensor:\n",
    "#         y0r, y0i = _lanes_to_BT(outs[0]); y1r, y1i = _lanes_to_BT(outs[1])\n",
    "#         s0r, s0i = _lanes_to_BT(yb[0]);   s1r, s1i = _lanes_to_BT(yb[1])\n",
    "#         r00 = 0.5*(_pearson_1d(y0r, s0r) + _pearson_1d(y0i, s0i))\n",
    "#         r11 = 0.5*(_pearson_1d(y1r, s1r) + _pearson_1d(y1i, s1i))\n",
    "#         r01 = 0.5*(_pearson_1d(y0r, s1r) + _pearson_1d(y0i, s1i))\n",
    "#         r10 = 0.5*(_pearson_1d(y1r, s0r) + _pearson_1d(y1i, s0i))\n",
    "#         best = torch.where(diag, r00 + r11, r01 + r10) * 0.5  # (B,)\n",
    "#         return best\n",
    "#     per_sample_r = _mean_r_for_pairing(choose_diag)  # (B,)\n",
    "\n",
    "#     # Choose which item to plot\n",
    "#     if pick == \"best\":\n",
    "#         b = int(torch.argmax(per_sample_r).item())\n",
    "#     elif isinstance(pick, int):\n",
    "#         b = int(pick)\n",
    "#     else:\n",
    "#         b = 0\n",
    "#     B = outs[0].size(0)\n",
    "#     b = max(0, min(b, B-1))\n",
    "\n",
    "#     # Build paired (pred, target) for the chosen sample\n",
    "#     diag = bool(choose_diag[b].item())\n",
    "\n",
    "#     def _extract_BT(x: torch.Tensor) -> np.ndarray:\n",
    "#         \"\"\"\n",
    "#         Convert (2,1,T) or (2,C,T) tensor to (2,T) numpy.\n",
    "#         - If C==1 -> squeeze channel\n",
    "#         - If C>1  -> average across channels\n",
    "#         \"\"\"\n",
    "#         if x.dim() != 3 or x.size(0) != 2:\n",
    "#             raise ValueError(f\"expected (2,C,T), got {tuple(x.shape)}\")\n",
    "#         if x.size(1) == 1:\n",
    "#             x = x[:, 0, :]            # (2,T)\n",
    "#         else:\n",
    "#             x = x.mean(dim=1)         # (2,T)\n",
    "#         return x.detach().cpu().numpy()\n",
    "\n",
    "#     y0 = _extract_BT(outs[0][b])\n",
    "#     y1 = _extract_BT(outs[1][b])\n",
    "#     s0 = _extract_BT(yb[0][b])\n",
    "#     s1 = _extract_BT(yb[1][b])\n",
    "\n",
    "#     # Apply pairing\n",
    "#     if diag:\n",
    "#         pairs = [(y0, s0, \"Source 1\"), (y1, s1, \"Source 2\")]\n",
    "#     else:\n",
    "#         pairs = [(y0, s1, \"Source 1 (paired with tgt2)\"),\n",
    "#                  (y1, s0, \"Source 2 (paired with tgt1)\")]\n",
    "\n",
    "#     # Plot real/imag overlays\n",
    "#     T = pairs[0][0].shape[-1]\n",
    "#     tmax = min(T, max_time) if max_time is not None else T\n",
    "#     tt = np.arange(tmax)\n",
    "\n",
    "#     fig, axes = plt.subplots(2, 2, figsize=(12,6), sharex=True)\n",
    "#     for k, (yp, yt, title) in enumerate(pairs):\n",
    "#         axes[k,0].plot(tt, yt[0, :tmax], lw=1.0, label=\"GT Real\")\n",
    "#         axes[k,0].plot(tt, yp[0, :tmax], lw=0.9, linestyle=\"--\", label=\"Pred Real\")\n",
    "#         axes[k,0].set_title(f\"{title} — Real\")\n",
    "#         axes[k,0].grid(alpha=0.3); axes[k,0].legend()\n",
    "\n",
    "#         axes[k,1].plot(tt, yt[1, :tmax], lw=1.0, label=\"GT Imag\")\n",
    "#         axes[k,1].plot(tt, yp[1, :tmax], lw=0.9, linestyle=\"--\", label=\"Pred Imag\")\n",
    "#         axes[k,1].set_title(f\"{title} — Imag\")\n",
    "#         axes[k,1].grid(alpha=0.3); axes[k,1].legend()\n",
    "\n",
    "#     plt.suptitle(f\"Predicted vs Ground Truth (sample {b}, \"\n",
    "#                  f\"{'diag' if diag else 'offdiag'} pairing, ρ={per_sample_r[b].item():.3f})\")\n",
    "#     plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "\n",
    "#     outp = save_dir / f\"pred_vs_gt_sample{b}.png\"\n",
    "#     plt.savefig(outp, dpi=150)\n",
    "#     if show: display(fig)\n",
    "#     plt.close(fig)\n",
    "#     print(f\"[saved] {outp}\")\n",
    "\n",
    "# # ----------------\n",
    "# # Run the plots\n",
    "# # ----------------\n",
    "# plot_training_curves(cfg.save_dir, history_in_mem=history if 'history' in globals() else None, show=True)\n",
    "# plot_pred_vs_gt(model, test_loader, device, cfg.save_dir, pick=\"best\", max_time=1024, show=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0992de09",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-12T16:03:41.473084Z",
     "iopub.status.busy": "2025-11-12T16:03:41.472957Z",
     "iopub.status.idle": "2025-11-12T16:03:41.475951Z",
     "shell.execute_reply": "2025-11-12T16:03:41.475003Z"
    }
   },
   "outputs": [],
   "source": [
    "# # --- ENV overrides for terminal runs ---\n",
    "# import os\n",
    "\n",
    "# def _env_bool(k, default=False):\n",
    "#     v = os.getenv(k)\n",
    "#     if v is None: return default\n",
    "#     return v.lower() in (\"1\",\"true\",\"yes\",\"y\",\"on\")\n",
    "\n",
    "# # MOD list (comma or space separated)\n",
    "# mods_env = os.getenv(\"MODS\")\n",
    "# if mods_env:\n",
    "#     # allow commas or spaces\n",
    "#     toks = [t for t in mods_env.replace(\",\", \" \").split() if t]\n",
    "#     TWO_MODS = toks\n",
    "\n",
    "# # core training knobs\n",
    "# cfg.epochs        = int(os.getenv(\"EPOCHS\",        cfg.epochs))\n",
    "# cfg.batch_size    = int(os.getenv(\"BATCH_SIZE\",    cfg.batch_size))\n",
    "# cfg.lr            = float(os.getenv(\"LR\",          cfg.lr))\n",
    "# cfg.weight_decay  = float(os.getenv(\"WEIGHT_DECAY\",cfg.weight_decay))\n",
    "# cfg.grad_clip     = float(os.getenv(\"GRAD_CLIP\",   cfg.grad_clip))\n",
    "# cfg.amp           = _env_bool(\"AMP\",               cfg.amp)\n",
    "# cfg.compile_model = _env_bool(\"COMPILE\",           cfg.compile_model)\n",
    "# cfg.log_interval  = int(os.getenv(\"LOG_INTERVAL\",  cfg.log_interval))\n",
    "\n",
    "# # model width/depth\n",
    "# MODEL_CHANNELS    = int(os.getenv(\"MODEL_CHANNELS\", 32))\n",
    "# MODEL_CHE_MID     = int(os.getenv(\"MODEL_CHE_MID\", 64))\n",
    "# MODEL_N_CDCM_A    = int(os.getenv(\"MODEL_N_CDCM_A\", 4))\n",
    "# MODEL_N_CDCM_B    = int(os.getenv(\"MODEL_N_CDCM_B\", 4))\n",
    "\n",
    "# # SNRs\n",
    "# if os.getenv(\"TRAINVAL_SNR\"):\n",
    "#     a,b = [float(x) for x in os.getenv(\"TRAINVAL_SNR\").split(\",\")]\n",
    "#     TRAINVAL_SNR_RANGE = (a,b)\n",
    "# if os.getenv(\"TEST_SNR\"):\n",
    "#     TEST_SNR = float(os.getenv(\"TEST_SNR\"))\n",
    "\n",
    "# # half sampling per (mod,SNR)\n",
    "# HALF_PER_MOD = _env_bool(\"HALF_PER_MOD\", False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scbss_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
