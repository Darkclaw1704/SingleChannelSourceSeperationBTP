{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "656ce275",
   "metadata": {},
   "source": [
    "TRANSFORMER FILE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0acba7d",
   "metadata": {},
   "source": [
    "The dpft_model.py file is an implementation of the transformer paper's blind source separation architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a541f742",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "FEATURE_DIM_N = 128\n",
    "N_HEADS = 2 \n",
    "KERNEL_SIZE = (4, 4)\n",
    "STRIDES = (2, 2)\n",
    "\n",
    "\n",
    "\n",
    "# N_FFT = 128  \n",
    "N_FFT=512\n",
    "# HOP_LENGTH = 128\n",
    "HOP_LENGTH = 256\n",
    "# ORIGINAL_LENGTH = 16384\n",
    "ORIGINAL_LENGTH = 65280\n",
    "\n",
    "\n",
    "DROPOUT_RATE = 0.1\n",
    "I_TRANSFORMER_LAYERS = 2\n",
    "J_DPTF_STACKS = 2\n",
    "\n",
    "def compute_stft_safe(x, n_fft=N_FFT, hop_length=HOP_LENGTH, win_length=None):\n",
    "    if win_length is None: win_length = n_fft\n",
    "    window = torch.hann_window(win_length, device=x.device)\n",
    "    \n",
    "    if x.shape[-1] < n_fft:\n",
    "        pad_amount = n_fft - x.shape[-1]\n",
    "        x = F.pad(x, (0, pad_amount))  \n",
    "    \n",
    "    Xm = torch.stft(\n",
    "        x, n_fft=n_fft, hop_length=hop_length, win_length=win_length,\n",
    "        window=window, return_complex=True\n",
    "    )\n",
    "    return Xm\n",
    "\n",
    "\n",
    "\n",
    "def preprocess_signal(xm):\n",
    "    \"\"\"\n",
    "    xm: [B, C, T]  (batch, channels, time)\n",
    "    Returns:\n",
    "        Xm2_4d: [B, 4, F_padded, T_new] - LogAmp/Phase stack\n",
    "        Xm_original_batched: [B, F, T_new] - Complex STFT of the *first* channel\n",
    "    \"\"\"\n",
    "    B, C, T_old = xm.shape\n",
    "    Xm2_4d_list = []\n",
    "    Xm_original_batched_list = []\n",
    "\n",
    "\n",
    "\n",
    "    for b in range(B):\n",
    "        sig_mix = xm[b, 0] \n",
    "        Xm_mix = compute_stft_safe(sig_mix) \n",
    "        Xm_original_batched_list.append(Xm_mix)\n",
    "        \n",
    "        F, T_new = Xm_mix.shape\n",
    "        F_padded = F + 1\n",
    "        \n",
    "        channel_features = []\n",
    "        for c in range(C):\n",
    "            sig = xm[b, c] \n",
    "            Xm_c = compute_stft_safe(sig) \n",
    "            Xm_c = torch.cat([Xm_c, torch.zeros(1, T_new, device=Xm_c.device)], dim=0)\n",
    "            Xm_abs = torch.abs(Xm_c)\n",
    "            Xm_logamp = torch.log10(torch.clamp(Xm_abs, min=1e-10))\n",
    "            Xm_phase = torch.angle(Xm_c)\n",
    "            channel_features.append(Xm_logamp)\n",
    "            channel_features.append(Xm_phase)  \n",
    "        Xm2_4d_list.append(torch.stack(channel_features, dim=0))\n",
    "    Xm2_4d = torch.stack(Xm2_4d_list, dim=0)\n",
    "    Xm_original_batched = torch.stack(Xm_original_batched_list, dim=0)\n",
    "    return Xm2_4d, Xm_original_batched \n",
    "\n",
    "\n",
    "\n",
    "def post_processing_block(Xs_4d,Xm_original_batched):\n",
    "    Xs_logamp = Xs_4d[:, :2] \n",
    "    Xs_phase = Xs_4d[:, 2:]  \n",
    "    Xs_linamp = torch.pow(10, Xs_logamp)\n",
    "    M_real = Xs_linamp * torch.cos(Xs_phase)\n",
    "    M_imag = Xs_linamp * torch.sin(Xs_phase)\n",
    "    Xo_4d_complex = torch.complex(M_real, M_imag)\n",
    "    Xo_4d_complex = Xo_4d_complex[:, :, :-1, :]\n",
    "    Xo1 = Xo_4d_complex[:, 0] \n",
    "    Xo2 = Xo_4d_complex[:, 1] \n",
    "    Xo1_separated = Xo1 * Xm_original_batched\n",
    "    Xo2_separated = Xo2 * Xm_original_batched\n",
    "    \n",
    "    return Xo1_separated, Xo2_separated\n",
    "\n",
    "def compute_istft(X, length=ORIGINAL_LENGTH):\n",
    "    window = torch.hann_window(N_FFT, device=X.device)\n",
    "    xm_out = torch.istft(\n",
    "        X, n_fft=N_FFT, hop_length=HOP_LENGTH, win_length=N_FFT,\n",
    "        window=window, return_complex=False, length=length\n",
    "    )\n",
    "    return xm_out.squeeze(0)\n",
    "\n",
    "\n",
    "\n",
    "class PermuteLayerNorm(nn.Module):\n",
    "    \"\"\"Applies LayerNorm over the feature dimension N after permuting [B, C, F, T] -> [B, F, T, C]\"\"\"\n",
    "    def __init__(self, normalized_shape):\n",
    "        super().__init__()\n",
    "        self.norm = nn.LayerNorm(normalized_shape)\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 3, 1)\n",
    "        x = self.norm(x)\n",
    "        x = x.permute(0, 3, 1, 2) \n",
    "        return x\n",
    "\n",
    "class SeparableConv2d(nn.Module):\n",
    "    \"\"\"\n",
    "    Simulates SeparableConv2D used in the paper (II.C)\n",
    "    The paper cites Keras/TensorFlow, which has a native separable layer.\n",
    "    In PyTorch, this is implemented as Depthwise followed by Pointwise convolution.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0):\n",
    "        super().__init__()\n",
    "        self.depthwise = nn.Conv2d(\n",
    "            in_channels, in_channels, kernel_size=kernel_size, stride=stride, padding=padding, groups=in_channels, bias=False\n",
    "        )\n",
    "        self.pointwise = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.pointwise(self.depthwise(x))\n",
    "\n",
    "\n",
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self, N=FEATURE_DIM_N, K=KERNEL_SIZE, S=STRIDES):\n",
    "        super().__init__()\n",
    "      \n",
    "\n",
    "        self.separable_conv1 = SeparableConv2d(2, N, kernel_size=K, stride=1, padding=(K[0]//2, K[1]//2))\n",
    "\n",
    "        self.norm1 = PermuteLayerNorm(N)\n",
    "      \n",
    "        self.separable_conv_down = SeparableConv2d(N, N, kernel_size=K, stride=S)\n",
    "        self.norm_down = PermuteLayerNorm(N)\n",
    "      \n",
    "        self.conv_final = nn.Conv2d(N, N, kernel_size=1)\n",
    "        self.norm_final = PermuteLayerNorm(N)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.norm1(self.separable_conv1(x))\n",
    "\n",
    "        x = self.norm_down(self.separable_conv_down(x))\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        Xe = self.norm_final(self.conv_final(x))\n",
    "        return Xe\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    \"\"\"Sinusoidal Positional Encoding as required by the paper (II.D, Eq. 8)\"\"\"\n",
    "    def __init__(self, dim, max_len=5000):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, dim)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, dim, 2).float() * (-math.log(10000.0) / dim))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, Z):\n",
    "        seq_len = Z.size(1)\n",
    "        E = self.pe[:seq_len, :Z.size(2)]\n",
    "        return Z + E.unsqueeze(0) \n",
    "\n",
    "\n",
    "class TransformerEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Implements I stacks of vanilla Transformer Encoder layers (Fig. 2c).\n",
    "    Applies g(.) I times.\n",
    "    \"\"\"\n",
    "    def __init__(self, dim, num_heads, dropout=DROPOUT_RATE, num_layers=I_TRANSFORMER_LAYERS):\n",
    "        super().__init__()\n",
    "        self.pos_encoder = PositionalEncoding(dim)\n",
    "\n",
    "        self.layers = nn.ModuleList([self._make_g_block(dim, num_heads, dropout) for _ in range(num_layers)])\n",
    "\n",
    "    def _make_g_block(self, dim, num_heads, dropout):\n",
    "        \"\"\"Implements the g(.) block (Eq. 9, 10)\"\"\"\n",
    "        return nn.ModuleList([\n",
    "            nn.MultiheadAttention(dim, num_heads, dropout=dropout, batch_first=True),\n",
    "            nn.LayerNorm(dim), \n",
    "            nn.Linear(dim, dim * 4),\n",
    "            nn.Linear(dim * 4, dim),\n",
    "            nn.LayerNorm(dim),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Dropout(dropout)\n",
    "        ])\n",
    "    \n",
    "    def forward(self, Z):\n",
    "    \n",
    "        Z_start = Z\n",
    "        Z1 = self.pos_encoder(Z) \n",
    "        Z_out = Z1\n",
    "        for mha, norm1, ffn1, ffn2, norm2, drop1, drop2 in self.layers:\n",
    "            residual1 = Z_out\n",
    "            attn_out, _ = mha(Z_out, Z_out, Z_out)\n",
    "            Z_out = norm1(residual1 + drop1(attn_out)) \n",
    "            \n",
    "            residual2 = Z_out\n",
    "            ffw_out = ffn2(F.relu(ffn1(Z_out)))\n",
    "            Z_out = norm2(residual2 + drop2(ffw_out))\n",
    "    \n",
    "        Z4 = Z_out + Z_start\n",
    "        return Z4\n",
    "\n",
    "\n",
    "class DPTFBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Implements the h(.) module: F-TE followed by T-TE (in series) (Fig. 2b)\n",
    "    Note: The paper implies shared weights across blocks (II.D)\n",
    "    \"\"\"\n",
    "    def __init__(self, N=FEATURE_DIM_N, H=N_HEADS):\n",
    "        super().__init__()\n",
    "        self.f_te = TransformerEncoder(N, H)\n",
    "        self.t_te = TransformerEncoder(N, H)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        B, N, F_p, T_p = x.shape \n",
    "        \n",
    "        x_freq = x.permute(0, 3, 2, 1).reshape(B * T_p, F_p, N)\n",
    "        x_freq = self.f_te(x_freq)\n",
    "        x_out = x_freq.reshape(B, T_p, F_p, N).permute(0, 3, 2, 1)\n",
    "\n",
    "        x_time = x_out.permute(0, 2, 3, 1).reshape(B * F_p, T_p, N)\n",
    "        x_time = self.t_te(x_time)\n",
    "        x_out = x_time.reshape(B, F_p, T_p, N).permute(0, 3, 1, 2)\n",
    "        \n",
    "        return x_out\n",
    "\n",
    "\n",
    "class FeatureTransformer(nn.Module):\n",
    "    \"\"\"The Feature Transformer block (Fig. 2a)\"\"\"\n",
    "    def __init__(self, N=FEATURE_DIM_N, num_stacks=J_DPTF_STACKS):\n",
    "        super().__init__()\n",
    "        self.transformer_blocks = nn.ModuleList([DPTFBlock(N) for _ in range(num_stacks)])\n",
    "        \n",
    "        self.conv_tanh = nn.Conv2d(N, N, kernel_size=1)\n",
    "        self.conv_sigmoid = nn.Conv2d(N, N, kernel_size=1)\n",
    "        self.conv_final = nn.Conv2d(N, N, kernel_size=1)\n",
    "        self.norm_final = PermuteLayerNorm(N)\n",
    "\n",
    "    def forward(self, x):\n",
    "        Xt1 = x\n",
    "        for block in self.transformer_blocks:\n",
    "            Xt1 = block(Xt1)\n",
    "            \n",
    "        tanh_out = torch.tanh(self.conv_tanh(Xt1))\n",
    "        sigmoid_out = torch.sigmoid(self.conv_sigmoid(Xt1))\n",
    "        Xt2 = tanh_out * sigmoid_out\n",
    "        \n",
    "        Xt = self.norm_final(self.conv_final(Xt2))\n",
    "        return Xt\n",
    "\n",
    "\n",
    "class Separator(nn.Module):\n",
    "    def __init__(self, N=FEATURE_DIM_N, K=KERNEL_SIZE, S=STRIDES):\n",
    "        super().__init__()\n",
    "        self.conv_up = nn.ConvTranspose2d(N, N, kernel_size=K, stride=S, output_padding=1)\n",
    "        self.norm1 = PermuteLayerNorm(N)\n",
    "    \n",
    "        self.conv_final = nn.Conv2d(N, 4, kernel_size=1) \n",
    "\n",
    "    def forward(self, x, F_padded, T):\n",
    "       \n",
    "        \n",
    "        x = self.conv_up(x)\n",
    "        \n",
    "        x = F.interpolate(x, size=(F_padded, T), mode='nearest')\n",
    "        \n",
    "        Xs1 = F.relu(self.norm1(x))\n",
    "        \n",
    "        Xs = self.conv_final(Xs1)\n",
    "        return Xs\n",
    "\n",
    "\n",
    "class DPFTSeparator(nn.Module):\n",
    "    def __init__(self, num_transformer_stacks=J_DPTF_STACKS):\n",
    "        super().__init__()\n",
    "        self.feature_extractor = FeatureExtractor()\n",
    "        self.feature_transformer = FeatureTransformer(num_stacks=num_transformer_stacks)\n",
    "        self.separator = Separator()\n",
    "        \n",
    "    def forward(self, xm):\n",
    "        Xm2_4d, Xm_original_batched = preprocess_signal(xm) \n",
    "        \n",
    "        B, C, F_padded, T = Xm2_4d.shape\n",
    "        Xe = self.feature_extractor(Xm2_4d)\n",
    "        Xt = self.feature_transformer(Xe)\n",
    "        Xs = self.separator(Xt, F_padded, T) \n",
    "        Xo1_separated, Xo2_separated = post_processing_block(Xs, Xm_original_batched)\n",
    "        xo1 = compute_istft(Xo1_separated)\n",
    "        xo2 = compute_istft(Xo2_separated)\n",
    "        \n",
    "        return xo1, xo2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed317362",
   "metadata": {},
   "source": [
    "This code uses the above transformer architecture for training of a model and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929ed3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import itertools\n",
    "import h5py\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader, Subset \n",
    "from dpft_model import DPFTSeparator \n",
    "from dpft_model import ORIGINAL_LENGTH\n",
    "import dpft_model\n",
    "\n",
    "# Model capacity is high (N=256, I=4, J=4) - ASSUMING these are set in dpft_model.py\n",
    "FRAMES_PER_SAMPLE = 64 # 64 * 1024 = 65,536 samples (Close to ORIGINAL_LENGTH)\n",
    "MAX_MIXTURES = 30 # Target max number of unique mixture samples\n",
    "BATCH_SIZE = 1# Keep this small (4-8) due to the large sequence length\n",
    "NUM_EPOCHS = 2 # Increased to allow for convergence\n",
    "\n",
    "# --- STFT/PLOTTING PARAMETERS ---\n",
    "N_FFT = 512\n",
    "HOP_SIZE = 256\n",
    "FS = 50e6 # Sample rate, assumed from paper's section III.B\n",
    "\n",
    "# --- LOSS FUNCTIONS (SD-SDR and uPIT-SDSDR) ---\n",
    "\n",
    "def sdsdr_loss(true_signal, estimated_signal):\n",
    "    # SD-SDR calculation (Standard Scale-Dependent SDR)\n",
    "    if true_signal.dim() == 0: true_signal = true_signal.unsqueeze(0)\n",
    "    if estimated_signal.dim() == 0: estimated_signal = estimated_signal.unsqueeze(0)\n",
    "    if true_signal.dim() == 1: true_signal = true_signal.unsqueeze(0)\n",
    "    if estimated_signal.dim() == 1: estimated_signal = estimated_signal.unsqueeze(0)\n",
    "    s = true_signal.view(-1)\n",
    "    s_hat = estimated_signal.view(-1)\n",
    "    \n",
    "    s_norm_sq = torch.sum(s * s)\n",
    "    s_s_hat_dot = torch.sum(s * s_hat)\n",
    "    \n",
    "    if s_norm_sq < 1e-8:\n",
    "        s_target = torch.zeros_like(s)\n",
    "    else:\n",
    "        scale = s_s_hat_dot / s_norm_sq\n",
    "        s_target = scale * s\n",
    "        \n",
    "    s_error = s_hat - s_target\n",
    "    s_target_norm_sq = torch.sum(s_target * s_target)\n",
    "    s_error_norm_sq = torch.sum(s_error * s_error)\n",
    "    epsilon = 1e-8\n",
    "    \n",
    "    sdsdr = 10 * torch.log10(s_target_norm_sq / (s_error_norm_sq + epsilon) + epsilon)\n",
    "    return sdsdr\n",
    "\n",
    "def uPIT_SDSDR_Loss(true_signals, estimated_signals):\n",
    "    \"\"\"Calculates uPIT loss based on SD-SDR (Eq. 21)\"\"\"\n",
    "    if true_signals.dim() == 2:\n",
    "        true_signals = true_signals.unsqueeze(0)\n",
    "    s_hat = torch.stack(estimated_signals, dim=1) \n",
    "    batch_size, num_channels, _ = true_signals.shape\n",
    "    \n",
    "    sd_sdr_matrix = torch.zeros(batch_size, num_channels, num_channels, device=true_signals.device)\n",
    "    for i in range(num_channels):\n",
    "        for j in range(num_channels):\n",
    "            s_i = true_signals[:, i, :].reshape(batch_size, -1)\n",
    "            s_hat_j = s_hat[:, j, :].reshape(batch_size, -1)\n",
    "            sdsdr_batch = []\n",
    "            for b in range(batch_size):\n",
    "                sdsdr_val = sdsdr_loss(s_i[b].flatten(), s_hat_j[b].flatten()) \n",
    "                sdsdr_batch.append(sdsdr_val)\n",
    "            sd_sdr_matrix[:, i, j] = torch.stack(sdsdr_batch)\n",
    "            \n",
    "    permutations = list(itertools.permutations(range(num_channels)))\n",
    "    max_avg_sdsdr = []\n",
    "    \n",
    "    for b in range(batch_size):\n",
    "        sdsdr_per_perm = []\n",
    "        for perm in permutations:\n",
    "            sdsr_sum = 0\n",
    "            for i in range(num_channels):\n",
    "                sdsr_sum += sd_sdr_matrix[b, i, perm[i]]\n",
    "            avg_sdsdr = sdsr_sum / num_channels\n",
    "            sdsdr_per_perm.append(avg_sdsdr)\n",
    "            \n",
    "        max_avg_sdsdr.append(torch.max(torch.stack(sdsdr_per_perm)))\n",
    "        \n",
    "    final_loss = -torch.mean(torch.stack(max_avg_sdsdr))\n",
    "    return final_loss\n",
    "\n",
    "# --- CUSTOM DATASET FOR ON-THE-FLY MIXING (MEMORY FIX) ---\n",
    "\n",
    "class BSSGenerationDataset(Dataset):\n",
    "    def __init__(self, I_all_frames, num_mixtures, target_length, frames_per_sample):\n",
    "        self.I_all_frames = I_all_frames # All 1024-sample frames\n",
    "        self.num_mixtures = num_mixtures\n",
    "        self.target_length = target_length\n",
    "        self.frames_per_sample = frames_per_sample\n",
    "        self.num_total_frames = I_all_frames.shape[0]\n",
    "\n",
    "        # Pre-generate random indices for each mixture to ensure fixed data split\n",
    "        # This requires 2 * frames_per_sample frames per mixture\n",
    "        self.frame_start_indices = np.random.randint(\n",
    "            0, self.num_total_frames - self.frames_per_sample, size=(num_mixtures, 2)\n",
    "        )\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.num_mixtures\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Retrieve pre-generated indices\n",
    "        start_idx1 = self.frame_start_indices[idx, 0]\n",
    "        start_idx2 = self.frame_start_indices[idx, 1]\n",
    "        \n",
    "        # 1. Concatenate Frames for S1 and S2\n",
    "        S1_frames = self.I_all_frames[start_idx1 : start_idx1 + self.frames_per_sample]\n",
    "        S2_frames = self.I_all_frames[start_idx2 : start_idx2 + self.frames_per_sample]\n",
    "        \n",
    "        # Flatten and truncate/pad to target_length (65280)\n",
    "        S1 = S1_frames.flatten()[:self.target_length]\n",
    "        S2 = S2_frames.flatten()[:self.target_length]\n",
    "        \n",
    "        # --- Data Preprocessing (Scaling, Noise, Normalization) ---\n",
    "        \n",
    "        # 3. Scale signals \n",
    "        s1_amp = np.random.uniform(0.1, 1.0)\n",
    "        s2_amp = np.random.uniform(0.1, 1.0)\n",
    "        S1_scaled = S1 * s1_amp\n",
    "        S2_scaled = S2 * s2_amp\n",
    "        \n",
    "        # 4. Corrupt with Gaussian noise\n",
    "        noise_level = np.random.uniform(0.001, 0.01)\n",
    "        noise = np.random.normal(0, noise_level, self.target_length).astype(np.float32)\n",
    "        \n",
    "        # 5. Mix the signals\n",
    "        X_M_i = S1_scaled + S2_scaled + noise \n",
    "        \n",
    "        # 6. Normalize\n",
    "        max_amp = np.max(np.abs(X_M_i))\n",
    "        if max_amp > 1e-8:\n",
    "            X_M_i /= max_amp\n",
    "            S1_norm = S1_scaled / max_amp\n",
    "            S2_norm = S2_scaled / max_amp\n",
    "        else:\n",
    "            S1_norm = S1_scaled\n",
    "            S2_norm = S2_scaled\n",
    "\n",
    "        # Convert to PyTorch tensors and ensure (C, L) shape\n",
    "        X_M_tensor = torch.tensor(X_M_i, dtype=torch.float32).unsqueeze(0) # (1, L)\n",
    "        Y_GT_tensor = torch.stack([\n",
    "            torch.tensor(S1_norm, dtype=torch.float32), \n",
    "            torch.tensor(S2_norm, dtype=torch.float32)\n",
    "        ], dim=0) # (2, L)\n",
    "        \n",
    "        return X_M_tensor, Y_GT_tensor\n",
    "\n",
    "# --- PLOTTING UTILITIES ---\n",
    "\n",
    "def compute_spectrogram(x, n_fft=N_FFT, hop_length=HOP_SIZE, fs=FS):\n",
    "    \"\"\"Computes and returns the magnitude spectrogram and frequency/time axis.\"\"\"\n",
    "    if x.dim() > 1: x = x.squeeze()\n",
    "    \n",
    "    window = torch.hann_window(n_fft, device=x.device)\n",
    "    if x.shape[-1] < n_fft:\n",
    "        pad_amount = n_fft - x.shape[-1]\n",
    "        x = F.pad(x, (0, pad_amount)) \n",
    "        \n",
    "    Xm = torch.stft(x, n_fft=n_fft, hop_length=hop_length, win_length=n_fft,\n",
    "                    window=window, return_complex=True, normalized=False)\n",
    "    \n",
    "    S_mag = torch.abs(Xm)\n",
    "    S_log = 10 * torch.log10(torch.clamp(S_mag, min=1e-10))\n",
    "    \n",
    "    freq_bins = S_log.shape[0]\n",
    "    time_bins = S_log.shape[1]\n",
    "    \n",
    "    # Frequency axis (MHz) and Time axis (ms)\n",
    "    freq_axis = np.linspace(0, fs / 2, freq_bins) / 1e6 \n",
    "    time_axis = np.linspace(0, (time_bins - 1) * hop_length / fs, time_bins) * 1e3 \n",
    "    \n",
    "    return S_log.cpu().numpy(), freq_axis, time_axis\n",
    "\n",
    "def plot_spectrograms(xm, s1, s2, xo1, xo2, sdsdr_val):\n",
    "    \"\"\"Plots the mixture, ground truth signals, and predicted separated signals as Log-Spectrograms.\"\"\"\n",
    "    \n",
    "    fig, axes = plt.subplots(3, 2, figsize=(12, 12))\n",
    "    plt.suptitle(f'Blind Source Separation Results\\nAvg Max SD-SDR: {sdsdr_val:.4f} dB', fontsize=16)\n",
    "    \n",
    "    signals = {\n",
    "        'Log-Spectrogram mixture': xm,\n",
    "        'Log-Spectrogram signal 1 (GT)': s1,\n",
    "        'Log-Spectrogram prediction 1': xo1,\n",
    "        'Log-Spectrogram signal 2 (GT)': s2,\n",
    "        'Log-Spectrogram prediction 2': xo2,\n",
    "    }\n",
    "\n",
    "    plot_order = [\n",
    "        ('Log-Spectrogram mixture', axes[0, 0]),\n",
    "        ('Log-Spectrogram signal 1 (GT)', axes[1, 0]),\n",
    "        ('Log-Spectrogram prediction 1', axes[1, 1]),\n",
    "        ('Log-Spectrogram signal 2 (GT)', axes[2, 0]),\n",
    "        ('Log-Spectrogram prediction 2', axes[2, 1]),\n",
    "    ]\n",
    "    \n",
    "    fig.delaxes(axes[0, 1]) \n",
    "    \n",
    "    # Plot Mixture\n",
    "    S_log_mix, freq_axis, time_axis = compute_spectrogram(signals['Log-Spectrogram mixture'])\n",
    "    S_log_mix = S_log_mix[:N_FFT//2 + 1, :]\n",
    "    ax = axes[0, 0]\n",
    "    im = ax.imshow(S_log_mix, aspect='auto', origin='lower',\n",
    "                   extent=[time_axis.min(), time_axis.max(), freq_axis.min(), freq_axis.max()],\n",
    "                   cmap='viridis')\n",
    "    ax.set_title(plot_order[0][0])\n",
    "    ax.set_xlabel('time (ms)')\n",
    "    ax.set_ylabel('freq (MHz)')\n",
    "    cbar_mix = fig.colorbar(im, ax=ax, orientation='vertical', pad=0.02)\n",
    "    cbar_mix.set_label('dB')\n",
    "    \n",
    "    # Plot Sources/Predictions\n",
    "    for i in range(1, len(plot_order)):\n",
    "        title, ax = plot_order[i]\n",
    "        signal = signals[title]\n",
    "        S_log, freq_axis, time_axis = compute_spectrogram(signal)\n",
    "        S_log = S_log[:N_FFT//2 + 1, :]\n",
    "\n",
    "        im = ax.imshow(S_log, aspect='auto', origin='lower',\n",
    "                       extent=[time_axis.min(), time_axis.max(), freq_axis.min(), freq_axis.max()],\n",
    "                       cmap='viridis')\n",
    "        ax.set_title(title)\n",
    "        ax.set_xlabel('time (ms)')\n",
    "        ax.set_ylabel('freq (MHz)')\n",
    "        \n",
    "        cbar = fig.colorbar(im, ax=ax, orientation='vertical', pad=0.02)\n",
    "        cbar.set_label('dB')\n",
    "        \n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    plt.savefig(\"separation_spectrograms.png\", dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "# --- MAIN EXECUTION BLOCK ---\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", DEVICE)\n",
    "\n",
    "h5_path = r\"/home/bss/data/GOLD_XYZ_OSC.0001_1024.hdf5\"\n",
    "\n",
    "try:\n",
    "    with h5py.File(h5_path, \"r\") as f:\n",
    "        print(\"Keys in HDF5 file:\", list(f.keys()))\n",
    "        X_all_np = f['X'][:]\n",
    "    I_all_frames = X_all_np[:, :, 0].astype(np.float32) \n",
    "    num_total_frames = I_all_frames.shape[0]\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: HDF5 file not found at {h5_path}. Cannot proceed without real data.\")\n",
    "    exit()\n",
    "\n",
    "# Filter is removed (using all frames) to ensure maximum data volume\n",
    "I_high_snr = I_all_frames \n",
    "\n",
    "max_feasible_mixtures = num_total_frames // (2 * FRAMES_PER_SAMPLE)\n",
    "NUM_MIXTURES = min(MAX_MIXTURES, max_feasible_mixtures)\n",
    "\n",
    "print(f\"Total frames: {num_total_frames}. High SNR (0dB+) frames selected: {num_total_frames}\")\n",
    "print(f\"Number of mixtures to generate: {NUM_MIXTURES}\")\n",
    "print(f\"Generating {NUM_MIXTURES} synthetic BSS samples by concatenating {FRAMES_PER_SAMPLE} frames.\")\n",
    "\n",
    "# --- DATASET AND LOADER SETUP ---\n",
    "\n",
    "# Instantiate the full dataset\n",
    "full_dataset = BSSGenerationDataset(\n",
    "    I_all_frames=I_high_snr,\n",
    "    num_mixtures=NUM_MIXTURES,\n",
    "    target_length=ORIGINAL_LENGTH,\n",
    "    frames_per_sample=FRAMES_PER_SAMPLE\n",
    ")\n",
    "\n",
    "all_indices = np.arange(NUM_MIXTURES)\n",
    "np.random.shuffle(all_indices)\n",
    "\n",
    "# Define splits\n",
    "train_split = int(0.8 * NUM_MIXTURES)\n",
    "val_split = int(0.9 * NUM_MIXTURES)\n",
    "\n",
    "train_indices = all_indices[:train_split]\n",
    "val_indices = all_indices[train_split:val_split]\n",
    "test_indices = all_indices[val_split:]\n",
    "\n",
    "print(f\"Dataset Split: Train={len(train_indices)}, Val={len(val_indices)}, Test={len(test_indices)}\")\n",
    "\n",
    "# Use Subset for splitting\n",
    "train_dataset = Subset(full_dataset, train_indices)\n",
    "val_dataset = Subset(full_dataset, val_indices)\n",
    "test_dataset = Subset(full_dataset, test_indices)\n",
    "\n",
    "# DataLoaders with multiprocessing (num_workers) for speed\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=1, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=1, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=1, pin_memory=True)\n",
    "\n",
    "# --- MODEL AND TRAINING SETUP ---\n",
    "\n",
    "def compute_stft_custom(xm, n_fft=N_FFT, hop_length=HOP_SIZE, win_length=None):\n",
    "    if win_length is None: win_length = n_fft\n",
    "    window = torch.hann_window(win_length, device=xm.device)\n",
    "    if xm.dim() > 2: xm = xm.squeeze(1) \n",
    "    \n",
    "    if xm.shape[-1] < n_fft:\n",
    "        pad_amount = n_fft - xm.shape[-1]\n",
    "        xm = F.pad(xm, (0, pad_amount)) \n",
    "        \n",
    "    Xm = torch.stft(xm, n_fft=n_fft, hop_length=hop_length, win_length=win_length,\n",
    "                    window=window, return_complex=True, normalized=False)\n",
    "    return Xm\n",
    "\n",
    "dpft_model.compute_stft = compute_stft_custom\n",
    "\n",
    "model = DPFTSeparator()\n",
    "model.to(DEVICE)\n",
    "criterion = uPIT_SDSDR_Loss\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "num_epochs = NUM_EPOCHS\n",
    "train_losses_history = [] \n",
    "val_losses_history = []\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "# --- TRAINING LOOP ---\n",
    "print(\"\\nStarting Training with uPIT-SDSDR Loss...\")\n",
    "for epoch in range(num_epochs):\n",
    "    model.train() \n",
    "    running_loss = 0.0\n",
    "    \n",
    "    # Decaying learning rate schedule (Eq. 22)\n",
    "    current_lr = 1e-4 * (0.90 ** epoch)\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = current_lr\n",
    "        \n",
    "    for batch_idx, (xm_batch, ym_batch) in enumerate(train_loader):\n",
    "        xm_batch = xm_batch.to(DEVICE) \n",
    "        ym_batch = ym_batch.to(DEVICE) \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        xo1, xo2 = model(xm_batch) \n",
    "        \n",
    "        xo1_safe = xo1.view(xm_batch.shape[0], -1) \n",
    "        xo2_safe = xo2.view(xm_batch.shape[0], -1)\n",
    "        \n",
    "        loss = criterion(ym_batch, [xo1_safe, xo2_safe])\n",
    "        \n",
    "        # ðŸš¨ Memory Optimization: Use torch.autocast/scaler if using mixed precision (optional but helpful)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    avg_train_loss = running_loss / len(train_loader)\n",
    "    train_losses_history.append(avg_train_loss)\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for xm_batch, ym_batch in val_loader:\n",
    "            xm_batch = xm_batch.to(DEVICE)\n",
    "            ym_batch = ym_batch.to(DEVICE)\n",
    "            \n",
    "            xo1, xo2 = model(xm_batch)\n",
    "            xo1_safe = xo1.view(xm_batch.shape[0], -1)\n",
    "            xo2_safe = xo2.view(xm_batch.shape[0], -1)\n",
    "            \n",
    "            loss = criterion(ym_batch, [xo1_safe, xo2_safe])\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    val_losses_history.append(avg_val_loss)\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], LR: {current_lr:.2e}, Train Loss: {avg_train_loss:.4f} dB, Val Loss: {avg_val_loss:.4f} dB\")\n",
    "    \n",
    "    # Save best model\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        torch.save(model.state_dict(), 'best_dpft_model.pth')\n",
    "        print(\"Model saved!\")\n",
    "\n",
    "print(\"Training complete.\")\n",
    "\n",
    "# --- TESTING AND PLOTTING ---\n",
    "print(\"\\nStarting Model Testing...\")\n",
    "try:\n",
    "    # ðŸš¨ Memory Safety: Ensure the model loads to the correct device\n",
    "    model.load_state_dict(torch.load('best_dpft_model.pth', map_location=DEVICE)) \n",
    "except FileNotFoundError:\n",
    "    print(\"Warning: Best model weights not found. Using final epoch weights.\")\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "total_sdsdr = 0.0\n",
    "sample_for_plotting = None\n",
    "sdsdr_for_plotting = 0.0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for xm_batch, ym_batch in test_loader:\n",
    "        xm_batch = xm_batch.to(DEVICE)\n",
    "        ym_batch = ym_batch.to(DEVICE)\n",
    "        \n",
    "        xo1, xo2 = model(xm_batch)\n",
    "        \n",
    "        xo1_safe = xo1.view(xm_batch.shape[0], -1)\n",
    "        xo2_safe = xo2.view(xm_batch.shape[0], -1)\n",
    "        \n",
    "        loss = criterion(ym_batch, [xo1_safe, xo2_safe])\n",
    "        test_loss += loss.item()\n",
    "        total_sdsdr += -loss.item() * xm_batch.shape[0] \n",
    "        \n",
    "        # Capture the first sample for plotting\n",
    "        if sample_for_plotting is None:\n",
    "            sample_for_plotting = (\n",
    "                xm_batch[0, 0].cpu(), \n",
    "                ym_batch[0, 0].cpu(), \n",
    "                ym_batch[0, 1].cpu(), \n",
    "                xo1_safe[0].cpu(), \n",
    "                xo2_safe[0].cpu()\n",
    "            )\n",
    "            single_sample_loss = -criterion(ym_batch[0].unsqueeze(0), [xo1_safe[0].unsqueeze(0), xo2_safe[0].unsqueeze(0)]).item()\n",
    "            sdsdr_for_plotting = single_sample_loss\n",
    "\n",
    "avg_test_loss = test_loss / len(test_loader)\n",
    "avg_test_sdsdr = total_sdsdr / len(test_indices)\n",
    "print(f\"\\n--- Test Results ---\")\n",
    "print(f\"Test Loss (Negative Avg SD-SDR): {avg_test_loss:.4f} dB\")\n",
    "print(f\"Average Max SD-SDR on Test Set: {avg_test_sdsdr:.4f} dB\")\n",
    "\n",
    "# --- Plotting ---\n",
    "plt.figure(figsize=(10, 6))\n",
    "epochs_range = range(1, num_epochs + 1)\n",
    "plt.plot(epochs_range, train_losses_history, label='Training Loss (-Avg SD-SDR)', color='blue')\n",
    "plt.plot(epochs_range, val_losses_history, label='Validation Loss (-Avg SD-SDR)', color='red')\n",
    "plt.title('Learning Curve (Negative Average SD-SDR) [cite: 256]')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss (dB)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(\"training_curve.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "if sample_for_plotting is not None:\n",
    "    xm, s1, s2, xo1, xo2 = sample_for_plotting\n",
    "    plot_spectrograms(xm, s1, s2, xo1, xo2, sdsdr_for_plotting)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d3ca1e",
   "metadata": {},
   "source": [
    "training code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7849727a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Import your model\n",
    "from dpft_model import DPFTSeparator, ORIGINAL_LENGTH\n",
    "import dpft_model\n",
    "\n",
    "# --- CONFIG ---\n",
    "H5_PATH = \"/home/bss/data/GOLD_XYZ_OSC.0001_1024.hdf5\"\n",
    "SPLIT_DIR = Path(\"/home/bss/dev/\")\n",
    "MODEL_PATH = \"best_dpft_model.pth\"\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "FRAMES_PER_SAMPLE = 64\n",
    "N_FFT = 512\n",
    "HOP_SIZE = 256\n",
    "\n",
    "# --- 1. RE-DEFINE DATASET (Must match training) ---\n",
    "class BSSFromIndicesDataset(Dataset):\n",
    "    def __init__(self, h5_data, valid_indices, num_mixtures, target_length, frames_per_sample):\n",
    "        self.data = h5_data\n",
    "        self.valid_indices = valid_indices\n",
    "        self.num_mixtures = num_mixtures\n",
    "        self.target_length = target_length\n",
    "        self.frames_per_sample = frames_per_sample\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.num_mixtures\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        rng = np.random.default_rng(seed=idx + len(self.valid_indices))\n",
    "        idx_s1 = rng.choice(self.valid_indices, size=self.frames_per_sample, replace=True)\n",
    "        idx_s2 = rng.choice(self.valid_indices, size=self.frames_per_sample, replace=True)\n",
    "        \n",
    "        frames_s1 = self.data[np.sort(idx_s1)][:, :, 0] \n",
    "        frames_s2 = self.data[np.sort(idx_s2)][:, :, 0]\n",
    "        \n",
    "        S1 = frames_s1.flatten()[:self.target_length]\n",
    "        S2 = frames_s2.flatten()[:self.target_length]\n",
    "        \n",
    "        s1_amp = rng.uniform(0.1, 1.0); S1_scaled = S1 * s1_amp\n",
    "        s2_amp = rng.uniform(0.1, 1.0); S2_scaled = S2 * s2_amp\n",
    "        noise = rng.normal(0, rng.uniform(0.001, 0.01), self.target_length).astype(np.float32)\n",
    "        X_M_i = S1_scaled + S2_scaled + noise\n",
    "        \n",
    "        max_amp = np.max(np.abs(X_M_i))\n",
    "        if max_amp > 1e-8:\n",
    "            X_M_i /= max_amp; S1_norm = S1_scaled / max_amp; S2_norm = S2_scaled / max_amp\n",
    "        else:\n",
    "            S1_norm, S2_norm = S1_scaled, S2_scaled\n",
    "\n",
    "        return (torch.tensor(X_M_i, dtype=torch.float32).unsqueeze(0), \n",
    "                torch.stack([torch.tensor(S1_norm), torch.tensor(S2_norm)]))\n",
    "\n",
    "# --- 2. SETUP MODEL & DATA ---\n",
    "# Monkey-patch STFT for model compatibility\n",
    "def compute_stft_custom(xm, n_fft=N_FFT, hop_length=HOP_SIZE, win_length=None):\n",
    "    if win_length is None: win_length = n_fft\n",
    "    window = torch.hann_window(win_length, device=xm.device)\n",
    "    if xm.dim() > 2: xm = xm.squeeze(1) \n",
    "    if xm.shape[-1] < n_fft: xm = F.pad(xm, (0, n_fft - xm.shape[-1])) \n",
    "    return torch.stft(xm, n_fft, hop_length, win_length, window, return_complex=True)\n",
    "\n",
    "dpft_model.compute_stft = compute_stft_custom\n",
    "\n",
    "print(\"Loading Data & Indices...\")\n",
    "f = h5py.File(H5_PATH, \"r\"); X_all = f['X'][:]; f.close()\n",
    "idx_test = np.load(SPLIT_DIR / \"test_indices.npy\")\n",
    "test_ds = BSSFromIndicesDataset(X_all, idx_test, 10, ORIGINAL_LENGTH, FRAMES_PER_SAMPLE) # Load 10 samples\n",
    "test_loader = DataLoader(test_ds, batch_size=1, shuffle=False)\n",
    "\n",
    "print(\"Loading Model...\")\n",
    "model = DPFTSeparator().to(DEVICE)\n",
    "try:\n",
    "    model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n",
    "    print(\"Weights Loaded âœ”\")\n",
    "except:\n",
    "    print(\"âš ï¸ Could not load weights. Using random init.\")\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# --- 3. GENERATE PLOTS ---\n",
    "print(\"Generating visualizations...\")\n",
    "# Get one batch (1 sample)\n",
    "xm, ym = next(iter(test_loader))\n",
    "xm, ym = xm.to(DEVICE), ym.to(DEVICE)\n",
    "\n",
    "with torch.no_grad():\n",
    "    xo1, xo2 = model(xm)\n",
    "    # Handle dimensions\n",
    "    if xo1.dim()==1: xo1 = xo1.unsqueeze(0)\n",
    "    if xo2.dim()==1: xo2 = xo2.unsqueeze(0)\n",
    "\n",
    "# Convert to Numpy for plotting\n",
    "mix = xm[0].cpu().numpy().flatten()\n",
    "s1_gt = ym[0,0].cpu().numpy().flatten()\n",
    "s2_gt = ym[0,1].cpu().numpy().flatten()\n",
    "s1_pred = xo1[0].cpu().numpy().flatten()\n",
    "s2_pred = xo2[0].cpu().numpy().flatten()\n",
    "\n",
    "# Plot 1: Waveforms\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.subplot(3, 1, 1); plt.plot(mix, color='grey'); plt.title(\"Input Mixture\"); plt.grid(alpha=0.3)\n",
    "plt.subplot(3, 1, 2); plt.plot(s1_gt, 'g', label='GT', alpha=0.6); plt.plot(s1_pred, 'k--', label='Pred', alpha=0.8); plt.title(\"Source 1\"); plt.legend()\n",
    "plt.subplot(3, 1, 3); plt.plot(s2_gt, 'b', label='GT', alpha=0.6); plt.plot(s2_pred, 'k--', label='Pred', alpha=0.8); plt.title(\"Source 2\"); plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"eval_waveforms_dpft.png\")\n",
    "print(\"Saved eval_waveforms_dpft.png\")\n",
    "\n",
    "# Plot 2: Spectrograms\n",
    "def plot_spec(ax, sig, title):\n",
    "    ax.specgram(sig, NFFT=256, Fs=1, noverlap=128, cmap='magma')\n",
    "    ax.set_title(title)\n",
    "\n",
    "fig, axes = plt.subplots(3, 2, figsize=(10, 10))\n",
    "# Row 1: Mix\n",
    "plot_spec(axes[0,0], mix, \"Mixture\")\n",
    "axes[0,1].axis('off')\n",
    "# Row 2: Source 1\n",
    "plot_spec(axes[1,0], s1_gt, \"GT Src 1\")\n",
    "plot_spec(axes[1,1], s1_pred, \"Pred Src 1\")\n",
    "# Row 3: Source 2\n",
    "plot_spec(axes[2,0], s2_gt, \"GT Src 2\")\n",
    "plot_spec(axes[2,1], s2_pred, \"Pred Src 2\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"eval_spectrograms_dpft.png\")\n",
    "print(\"Saved eval_spectrograms_dpft.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
